{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65afc5c6-4f4d-4c8d-b6fc-2d5bd3dbd2fa",
   "metadata": {},
   "source": [
    "This file is to test my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "145684f6-e426-480d-bad6-dd7d86f3b54b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-04T22:12:41.488875Z",
     "iopub.status.busy": "2023-04-04T22:12:41.488364Z",
     "iopub.status.idle": "2023-04-04T22:12:41.505432Z",
     "shell.execute_reply": "2023-04-04T22:12:41.503718Z",
     "shell.execute_reply.started": "2023-04-04T22:12:41.488831Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_python_script = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc0c4737-aff1-41f8-a4ca-9c9659dd7512",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-04T22:12:42.904515Z",
     "iopub.status.busy": "2023-04-04T22:12:42.903857Z",
     "iopub.status.idle": "2023-04-04T22:12:43.029638Z",
     "shell.execute_reply": "2023-04-04T22:12:43.028993Z",
     "shell.execute_reply.started": "2023-04-04T22:12:42.904469Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../mypkg\")\n",
    "from constants import RES_ROOT, FIG_ROOT, DATA_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd0b2ec3-922a-40d5-ad69-4701aa9ad1fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-04T22:12:44.827927Z",
     "iopub.status.busy": "2023-04-04T22:12:44.827231Z",
     "iopub.status.idle": "2023-04-04T22:12:45.703937Z",
     "shell.execute_reply": "2023-04-04T22:12:45.702794Z",
     "shell.execute_reply.started": "2023-04-04T22:12:44.827878Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from easydict import EasyDict as edict\n",
    "import time\n",
    "\n",
    "if not run_python_script:\n",
    "    plt.style.use(FIG_ROOT/\"base.mplstyle\")\n",
    "    %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "612a1577-8d0c-4c34-991f-aecadd00c783",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-04T22:12:47.113180Z",
     "iopub.status.busy": "2023-04-04T22:12:47.112415Z",
     "iopub.status.idle": "2023-04-04T22:12:48.527816Z",
     "shell.execute_reply": "2023-04-04T22:12:48.526810Z",
     "shell.execute_reply.started": "2023-04-04T22:12:47.113130Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'models.main_model' from '/data/rajlab1/user_data/jin/MyResearch/gTVDN-NN/notebooks/../mypkg/models/main_model.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import models.main_model\n",
    "importlib.reload(models.main_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "870bf723-ebfa-4975-adad-53279ce21e0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-04T22:13:07.660910Z",
     "iopub.status.busy": "2023-04-04T22:13:07.660265Z",
     "iopub.status.idle": "2023-04-04T22:13:07.666763Z",
     "shell.execute_reply": "2023-04-04T22:13:07.665657Z",
     "shell.execute_reply.started": "2023-04-04T22:13:07.660858Z"
    },
    "tags": [
     "mypkg"
    ]
   },
   "outputs": [],
   "source": [
    "from models.main_model import myNet\n",
    "from utils.misc import delta_time, load_pkl_folder2dict, save_pkl_dict2folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c0dd819-8b02-4c78-b283-633dd643a7a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-04T22:13:08.396056Z",
     "iopub.status.busy": "2023-04-04T22:13:08.395501Z",
     "iopub.status.idle": "2023-04-04T22:13:08.405050Z",
     "shell.execute_reply": "2023-04-04T22:13:08.403822Z",
     "shell.execute_reply.started": "2023-04-04T22:13:08.396012Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pkgs for pytorch (on Apr 3, 2023)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.functional import F\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(2)\n",
    "    torch.set_default_tensor_type(torch.cuda.DoubleTensor)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02de0efb-9a2e-48bf-81b5-751dac594be6",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ead23831-9b80-4e55-ab4d-469817776500",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-04T22:13:09.810244Z",
     "iopub.status.busy": "2023-04-04T22:13:09.809608Z",
     "iopub.status.idle": "2023-04-04T22:13:09.820795Z",
     "shell.execute_reply": "2023-04-04T22:13:09.819684Z",
     "shell.execute_reply.started": "2023-04-04T22:13:09.810199Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "AD_dir = DATA_ROOT/\"AD_data\"\n",
    "ctrl_p1 = list(AD_dir.glob(\"70*.mat\"))[0]\n",
    "ctrl_p2 = list(AD_dir.glob(\"time*.mat\"))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e32cb72c-7763-4298-8cd5-332fbaa14eb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-04T22:13:10.230891Z",
     "iopub.status.busy": "2023-04-04T22:13:10.230297Z",
     "iopub.status.idle": "2023-04-04T22:13:16.046102Z",
     "shell.execute_reply": "2023-04-04T22:13:16.045232Z",
     "shell.execute_reply.started": "2023-04-04T22:13:10.230845Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import mat73\n",
    "\n",
    "data_p1 = loadmat(ctrl_p1)[\"dk10\"]\n",
    "data_p2 = mat73.loadmat(ctrl_p2)[\"dk10\"]\n",
    "data = np.concatenate([data_p1,  data_p2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28ea4114-fb3a-453d-97ff-35391b0fbba3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-04T22:13:16.047898Z",
     "iopub.status.busy": "2023-04-04T22:13:16.047531Z",
     "iopub.status.idle": "2023-04-04T22:13:20.698923Z",
     "shell.execute_reply": "2023-04-04T22:13:20.697943Z",
     "shell.execute_reply.started": "2023-04-04T22:13:16.047868Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.signal import detrend\n",
    "# detrend the data\n",
    "data = detrend(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2081c50f-9135-4bd4-b23d-35cf5d423f0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-04T22:13:20.699712Z",
     "iopub.status.busy": "2023-04-04T22:13:20.699550Z",
     "iopub.status.idle": "2023-04-04T22:13:20.702663Z",
     "shell.execute_reply": "2023-04-04T22:13:20.702246Z",
     "shell.execute_reply.started": "2023-04-04T22:13:20.699699Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data = data[-22:].transpose(0, 2, 1)\n",
    "train_data = data[:-22].transpose(0, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8a8444-1c37-4323-b1d9-bc033dcc584e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e86c794-a9ec-4239-8a21-e0369672fa9a",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97b4f59b-7544-465a-9cf5-68091ecc2198",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-04T22:13:20.703901Z",
     "iopub.status.busy": "2023-04-04T22:13:20.703665Z",
     "iopub.status.idle": "2023-04-04T22:13:20.725307Z",
     "shell.execute_reply": "2023-04-04T22:13:20.724682Z",
     "shell.execute_reply.started": "2023-04-04T22:13:20.703888Z"
    },
    "tags": [
     "fns"
    ]
   },
   "outputs": [],
   "source": [
    "def get_batch(dataset, batch_size, block_size):\n",
    "    sub_ix = torch.randint(len(dataset), (1, ))\n",
    "    ix = torch.randint(len(dataset[sub_ix]) - block_size, (batch_size,))\n",
    "    x = torch.stack([torch.from_numpy((dataset[sub_ix, i:i+block_size])) for i in ix])\n",
    "    y = torch.stack([torch.from_numpy((dataset[sub_ix, i+1:i+1+block_size])) for i in ix])\n",
    "    if device.type == 'cuda':\n",
    "        # pin arrays x,y, which allows us to move them to GPU asynchronously (non_blocking=True)\n",
    "        x, y = x.pin_memory().to(device, non_blocking=True), y.pin_memory().to(device, non_blocking=True)\n",
    "    else:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "    return x.double(), y.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ded80283-4710-4e1b-a29e-e2d90c600984",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-04T22:13:20.726282Z",
     "iopub.status.busy": "2023-04-04T22:13:20.726057Z",
     "iopub.status.idle": "2023-04-04T22:13:20.753512Z",
     "shell.execute_reply": "2023-04-04T22:13:20.752638Z",
     "shell.execute_reply.started": "2023-04-04T22:13:20.726263Z"
    },
    "tags": [
     "fns"
    ]
   },
   "outputs": [],
   "source": [
    "def generate_position_encode(block_size, nfeature):\n",
    "    # create a matrix with shape (blocksize, nfeature)\n",
    "    position = torch.arange(block_size, dtype=torch.float).unsqueeze(1)\n",
    "    div_term = torch.exp(torch.arange(0, nfeature, 2).float() * (-np.log(10000.0) / nfeature))\n",
    "    # apply sine to even indices in the array\n",
    "    pos_enc = torch.zeros((block_size, nfeature))\n",
    "    pos_enc[:, 0::2] = torch.sin(position * div_term)\n",
    "    # apply cosine to odd indices in the array\n",
    "    pos_enc[:, 1::2] = torch.cos(position * div_term)\n",
    "    return pos_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01a6636d-568d-4c69-a777-2cf29c030332",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-04T22:14:46.598020Z",
     "iopub.status.busy": "2023-04-04T22:14:46.597381Z",
     "iopub.status.idle": "2023-04-04T22:14:46.608123Z",
     "shell.execute_reply": "2023-04-04T22:14:46.606901Z",
     "shell.execute_reply.started": "2023-04-04T22:14:46.597972Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def out2pred(net_out, X):\n",
    "    A_mats = net_out.reshape(config.batch_size, config.block_size, paras.nroi, -1)\n",
    "    Y_pred = (A_mats @ X.unsqueeze(-1)).squeeze()\n",
    "    return Y_pred\n",
    "\n",
    "def evaluate(net):\n",
    "    X_test, Y_test = get_batch(test_data, \n",
    "                     batch_size=config.batch_size,  \n",
    "                     block_size=config.block_size)\n",
    "    X_test = X_test + pos_enc\n",
    "    net.eval()\n",
    "    net_out = net(X_test)\n",
    "    Y_pred = out2pred(net_out, X_test)\n",
    "    loss = loss_fn(Y_test, Y_pred)\n",
    "    net.train()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44d38d87-d50a-45e9-97ff-c2cde38024ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-04T22:32:28.559988Z",
     "iopub.status.busy": "2023-04-04T22:32:28.559362Z",
     "iopub.status.idle": "2023-04-04T22:32:28.570754Z",
     "shell.execute_reply": "2023-04-04T22:32:28.569512Z",
     "shell.execute_reply.started": "2023-04-04T22:32:28.559942Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "paras = edict()\n",
    "paras.nroi = data.shape[1]\n",
    "\n",
    "config = edict()\n",
    "config.nfeature = paras.nroi # the dim of features at each time point\n",
    "config.ndim = 256 # the output of the first FC layer\n",
    "config.target_dim = paras.nroi * paras.nroi # the target dim \n",
    "config.dropout = 0.5 # the dropout rate\n",
    "config.n_layer = 1 # the number of self-attention layers\n",
    "config.n_head = 8 # numher of heads for multi-head attention\n",
    "config.is_mask = True # Use mask to make the attention causal\n",
    "config.is_bias = True # Bias  for layernorm\n",
    "config.block_size = 256 # the preset length of seq, \n",
    "config.batch_size = 32 # the preset length of seq, \n",
    "\n",
    "paras_train = edict()\n",
    "paras_train.batch_size = 64\n",
    "paras_train.niter = 500\n",
    "paras_train.loss_out = 10\n",
    "paras_train.clip = 1 # \n",
    "paras_train.lr_step = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "61bd2a81-8395-4235-94b0-a336d89e0d9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-04T23:05:34.916048Z",
     "iopub.status.busy": "2023-04-04T23:05:34.915420Z",
     "iopub.status.idle": "2023-04-04T23:05:34.922859Z",
     "shell.execute_reply": "2023-04-04T23:05:34.921579Z",
     "shell.execute_reply.started": "2023-04-04T23:05:34.915999Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def trunc_mse_loss(Y, Y_pred):\n",
    "    diff = (Y - Y_pred)\n",
    "    #abs_diff = torch.abs(Y - Y_pred)\n",
    "    #v = torch.mean(abs_diff[abs_diff < (abs_diff.mean()+1*abs_diff.std())]**2)\n",
    "    return (diff**2).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0ed6692b-f81b-4023-a3a5-a87e1b9a6913",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-04T23:05:35.534906Z",
     "iopub.status.busy": "2023-04-04T23:05:35.534064Z",
     "iopub.status.idle": "2023-04-04T23:05:35.654991Z",
     "shell.execute_reply": "2023-04-04T23:05:35.654473Z",
     "shell.execute_reply.started": "2023-04-04T23:05:35.534858Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 1.99M\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    }
   ],
   "source": [
    "net = myNet(config)\n",
    "pos_enc = generate_position_encode(config.block_size, config.nfeature).unsqueeze(0)\n",
    "\n",
    "loss_fn = nn.MSELoss(reduction=\"none\")\n",
    "loss_fn = trunc_mse_loss\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-4, weight_decay=0)\n",
    "scheduler = ExponentialLR(optimizer, gamma=0.3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdb1b30-296d-422f-bf17-496d08711c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "423.27496\n",
      "439.4143\n",
      "700.7775\n",
      "625.4858\n",
      "21543.672\n",
      "11648.712\n",
      "34832.87\n",
      "16833.91\n",
      "23408.102\n",
      "12655.108\n",
      "18435.816\n",
      "26397.918\n",
      "26156.062\n",
      "7215.761\n",
      "24.011957\n",
      "14644.457\n",
      "19681.895\n",
      "4.353186\n",
      "10223.101\n",
      "3.3560998\n",
      "59921.79\n",
      "18277.637\n",
      "18.830772\n",
      "19764.154\n",
      "10978.8955\n",
      "13510.064\n",
      "350.7893\n",
      "5.863027\n",
      "5922.1562\n",
      "12403.258\n",
      "31.640512\n",
      "12133.332\n",
      "19325.607\n",
      "37.073875\n",
      "6079.2764\n",
      "935.894\n",
      "393.42087\n",
      "10218.475\n",
      "3359.081\n",
      "573.54126\n",
      "648.3074\n",
      "182.9855\n",
      "694.2041\n",
      "1024.4565\n",
      "494.40796\n",
      "647.30786\n",
      "497.86935\n",
      "750.86505\n",
      "1049.2618\n",
      "642.30444\n",
      "452.81525\n",
      "560.69257\n",
      "373.29852\n",
      "476.28067\n",
      "445.18692\n",
      "683.4876\n",
      "5988.1274\n",
      "232.03542\n",
      "4189.432\n",
      "5786.858\n",
      "6975.1284\n",
      "7634.328\n",
      "4637.701\n",
      "7961.357\n",
      "184.34195\n",
      "10747.301\n",
      "14998.881\n",
      "11651.636\n",
      "10691.651\n",
      "14561.659\n",
      "13065.513\n",
      "14040.728\n",
      "22865.3\n",
      "16305.5\n",
      "23018.973\n",
      "24788.496\n",
      "12136.742\n",
      "19260.182\n",
      "7990.7964\n",
      "19205.566\n",
      "3081.7654\n",
      "17674.361\n",
      "6906.54\n",
      "1532.1886\n",
      "7642.5674\n",
      "20554.59\n",
      "31848.992\n",
      "11692.671\n",
      "36031.18\n",
      "14564.424\n",
      "6881.456\n",
      "7712.752\n"
     ]
    }
   ],
   "source": [
    "dat1 = data[0]\n",
    "for ix in range(92):\n",
    "    print(data[ix].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcf7dd7-7bd0-48b4-ac27-0e20007c1206",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1b16dbf1-1714-4653-8279-d7ead4739edf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-04T23:05:37.320506Z",
     "iopub.status.busy": "2023-04-04T23:05:37.319793Z",
     "iopub.status.idle": "2023-04-04T23:12:23.498523Z",
     "shell.execute_reply": "2023-04-04T23:12:23.498083Z",
     "shell.execute_reply.started": "2023-04-04T23:05:37.320453Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iter 10/500, the losses are 2.71201E+08 (train). the losses are 3.47161E+08 (test). The time used is 7.969s. \n",
      "At iter 20/500, the losses are 2.68217E+08 (train). the losses are 3.20031E+08 (test). The time used is 6.554s. \n",
      "At iter 30/500, the losses are 4.43794E+08 (train). the losses are 4.20303E+08 (test). The time used is 8.198s. \n",
      "At iter 40/500, the losses are 4.19364E+08 (train). the losses are 6.41405E+08 (test). The time used is 7.147s. \n",
      "At iter 50/500, the losses are 1.91561E+08 (train). the losses are 1.05919E+08 (test). The time used is 8.997s. \n",
      "At iter 60/500, the losses are 1.06907E+08 (train). the losses are 4.95904E+08 (test). The time used is 9.049s. \n",
      "At iter 70/500, the losses are 6.72639E+08 (train). the losses are 1.79605E+07 (test). The time used is 9.060s. \n",
      "At iter 80/500, the losses are 2.74807E+08 (train). the losses are 1.85639E+08 (test). The time used is 7.485s. \n",
      "At iter 90/500, the losses are 3.41928E+08 (train). the losses are 1.00795E+08 (test). The time used is 8.889s. \n",
      "At iter 100/500, the losses are 2.59796E+08 (train). the losses are 2.04380E+08 (test). The time used is 9.069s. \n",
      "At iter 110/500, the losses are 3.42009E+07 (train). the losses are 3.60606E+09 (test). The time used is 9.033s. \n",
      "At iter 120/500, the losses are 3.61788E+08 (train). the losses are 3.90967E+08 (test). The time used is 8.598s. \n",
      "At iter 130/500, the losses are 7.93910E+08 (train). the losses are 9.97056E+07 (test). The time used is 7.803s. \n",
      "At iter 140/500, the losses are 1.57371E+08 (train). the losses are 3.89773E+08 (test). The time used is 8.319s. \n",
      "At iter 150/500, the losses are 8.14521E+07 (train). the losses are 5.93603E+06 (test). The time used is 8.309s. \n",
      "At iter 160/500, the losses are 2.01340E+08 (train). the losses are 3.88689E+07 (test). The time used is 8.214s. \n",
      "At iter 170/500, the losses are 1.96326E+08 (train). the losses are 5.08906E+08 (test). The time used is 8.176s. \n",
      "At iter 180/500, the losses are 2.32163E+08 (train). the losses are 1.97997E+08 (test). The time used is 6.607s. \n",
      "At iter 190/500, the losses are 4.59523E+08 (train). the losses are 1.15166E+08 (test). The time used is 6.527s. \n",
      "At iter 200/500, the losses are 9.85247E+07 (train). the losses are 3.22033E+08 (test). The time used is 8.435s. \n",
      "At iter 210/500, the losses are 2.73966E+08 (train). the losses are 5.32385E+08 (test). The time used is 8.633s. \n",
      "At iter 220/500, the losses are 1.52924E+08 (train). the losses are 9.95142E+08 (test). The time used is 7.653s. \n",
      "At iter 230/500, the losses are 3.80581E+08 (train). the losses are 9.14464E+08 (test). The time used is 8.398s. \n",
      "At iter 240/500, the losses are 2.98662E+08 (train). the losses are 2.80012E+08 (test). The time used is 8.348s. \n",
      "At iter 250/500, the losses are 1.62251E+08 (train). the losses are 3.58658E+09 (test). The time used is 7.560s. \n",
      "At iter 260/500, the losses are 1.99187E+08 (train). the losses are 3.73547E+09 (test). The time used is 7.546s. \n",
      "At iter 270/500, the losses are 1.35494E+08 (train). the losses are 9.36747E+07 (test). The time used is 8.633s. \n",
      "At iter 280/500, the losses are 1.25229E+08 (train). the losses are 1.07120E+09 (test). The time used is 8.398s. \n",
      "At iter 290/500, the losses are 3.78909E+08 (train). the losses are 1.87086E+08 (test). The time used is 8.382s. \n",
      "At iter 300/500, the losses are 1.32131E+08 (train). the losses are 4.79729E+08 (test). The time used is 9.008s. \n",
      "At iter 310/500, the losses are 4.62792E+08 (train). the losses are 6.45812E+07 (test). The time used is 8.825s. \n",
      "At iter 320/500, the losses are 3.34740E+08 (train). the losses are 9.77141E+07 (test). The time used is 8.245s. \n",
      "At iter 330/500, the losses are 9.19474E+08 (train). the losses are 8.98950E+08 (test). The time used is 8.569s. \n",
      "At iter 340/500, the losses are 4.67326E+08 (train). the losses are 7.46561E+08 (test). The time used is 8.025s. \n",
      "At iter 350/500, the losses are 1.96166E+08 (train). the losses are 2.47036E+09 (test). The time used is 8.549s. \n",
      "At iter 360/500, the losses are 3.85530E+08 (train). the losses are 3.62383E+09 (test). The time used is 8.222s. \n",
      "At iter 370/500, the losses are 1.15838E+08 (train). the losses are 2.49958E+08 (test). The time used is 7.937s. \n",
      "At iter 380/500, the losses are 2.85773E+08 (train). the losses are 2.69286E+08 (test). The time used is 8.377s. \n",
      "At iter 390/500, the losses are 2.18928E+08 (train). the losses are 1.17524E+09 (test). The time used is 7.227s. \n",
      "At iter 400/500, the losses are 4.94221E+08 (train). the losses are 9.04296E+07 (test). The time used is 6.933s. \n",
      "At iter 410/500, the losses are 5.33186E+08 (train). the losses are 4.42235E+08 (test). The time used is 6.608s. \n",
      "At iter 420/500, the losses are 1.03267E+08 (train). the losses are 3.24659E+07 (test). The time used is 6.585s. \n",
      "At iter 430/500, the losses are 2.53602E+07 (train). the losses are 7.54270E+08 (test). The time used is 8.445s. \n",
      "At iter 440/500, the losses are 3.35824E+08 (train). the losses are 2.84499E+09 (test). The time used is 9.013s. \n",
      "At iter 450/500, the losses are 1.34095E+09 (train). the losses are 6.56885E+08 (test). The time used is 8.953s. \n",
      "At iter 460/500, the losses are 2.68569E+08 (train). the losses are 3.77851E+07 (test). The time used is 8.503s. \n",
      "At iter 470/500, the losses are 1.31989E+08 (train). the losses are 6.12208E+08 (test). The time used is 7.130s. \n",
      "At iter 480/500, the losses are 2.82854E+08 (train). the losses are 7.49092E+08 (test). The time used is 8.183s. \n",
      "At iter 490/500, the losses are 2.61622E+08 (train). the losses are 7.25613E+08 (test). The time used is 8.435s. \n",
      "At iter 500/500, the losses are 1.01676E+09 (train). the losses are 8.20660E+08 (test). The time used is 8.398s. \n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "loss_cur = 0\n",
    "losses = []\n",
    "losses_test = []\n",
    "\n",
    "t0 = time.time()\n",
    "for ix in range(paras_train.niter):\n",
    "    X, Y = get_batch(train_data, \n",
    "                      batch_size=config.batch_size,  \n",
    "                      block_size=config.block_size)\n",
    "    X = X + pos_enc\n",
    "    # Zero the gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    net_out = net(X)\n",
    "    Y_pred = out2pred(net_out, X)\n",
    "    loss = loss_fn(Y, Y_pred)\n",
    "    \n",
    "    # Perform backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    torch.nn.utils.clip_grad_norm_(net.parameters(), paras_train.clip)\n",
    "    # Perform optimization\n",
    "    optimizer.step()\n",
    "    \n",
    "    loss_cur = loss_cur + loss.item()\n",
    "    if ix % paras_train.loss_out == (paras_train.loss_out-1):\n",
    "        losses.append(loss_cur/paras_train.loss_out)\n",
    "        losses_test.append(evaluate(net))\n",
    "        print(f\"At iter {ix+1}/{paras_train.niter}, \"\n",
    "              f\"the losses are {loss_cur/paras_train.loss_out:.5E} (train). \"\n",
    "              f\"the losses are {losses_test[-1]:.5E} (test). \"\n",
    "              f\"The time used is {delta_time(t0):.3f}s. \"\n",
    "             )\n",
    "        loss_cur = 0\n",
    "        t0 = time.time()\n",
    "    \n",
    "    #if ix % paras_train.lr_step == (paras_train.lr_step-1):\n",
    "    #    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65875a4b-e777-4e79-a347-1766e7c16624",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": true,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
