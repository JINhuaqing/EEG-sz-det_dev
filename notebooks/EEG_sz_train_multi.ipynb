{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65afc5c6-4f4d-4c8d-b6fc-2d5bd3dbd2fa",
   "metadata": {},
   "source": [
    "This file is to test my model on the TUH-EEG-seizure data\n",
    "\n",
    "In this file, I train the model with two loss, \n",
    "\n",
    "- loss1: the loss predicting X_t1, X_t2, ... from X_{t-1}, predict multiple step\n",
    "- loss2: the loss predicting seizure label from X_t\n",
    "\n",
    "Note that I always discretize X into 2^K classes, so the loss1 is also a classification loss.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db156fe5",
   "metadata": {},
   "source": [
    "# Pre-params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "145684f6-e426-480d-bad6-dd7d86f3b54b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T01:06:49.518438Z",
     "iopub.status.busy": "2024-05-25T01:06:49.517863Z",
     "iopub.status.idle": "2024-05-25T01:06:49.537388Z",
     "shell.execute_reply": "2024-05-25T01:06:49.536748Z",
     "shell.execute_reply.started": "2024-05-25T01:06:49.518395Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my_net_multistep.py'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME = \"test\"\n",
    "SAVED_MODEL = None\n",
    "MODEL_CLASS = \"my_net_multi.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354c8de0",
   "metadata": {},
   "source": [
    "# Load pkgs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc0c4737-aff1-41f8-a4ca-9c9659dd7512",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T01:06:52.181580Z",
     "iopub.status.busy": "2024-05-25T01:06:52.180738Z",
     "iopub.status.idle": "2024-05-25T01:06:52.357241Z",
     "shell.execute_reply": "2024-05-25T01:06:52.356203Z",
     "shell.execute_reply.started": "2024-05-25T01:06:52.181535Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../mypkg\")\n",
    "from constants import RES_ROOT, FIG_ROOT, DATA_ROOT, MODEL_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd0b2ec3-922a-40d5-ad69-4701aa9ad1fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T01:06:52.534996Z",
     "iopub.status.busy": "2024-05-25T01:06:52.534040Z",
     "iopub.status.idle": "2024-05-25T01:06:54.580506Z",
     "shell.execute_reply": "2024-05-25T01:06:54.579327Z",
     "shell.execute_reply.started": "2024-05-25T01:06:52.534947Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from easydict import EasyDict as edict\n",
    "from collections import defaultdict as ddict\n",
    "import time\n",
    "# copy file\n",
    "import shutil\n",
    "from pprint import pprint\n",
    "\n",
    "plt.style.use(FIG_ROOT/\"base.mplstyle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "713768d1-2305-4ef8-9473-3672cd14a095",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T01:06:55.004103Z",
     "iopub.status.busy": "2024-05-25T01:06:55.002793Z",
     "iopub.status.idle": "2024-05-25T01:06:55.067510Z",
     "shell.execute_reply": "2024-05-25T01:06:55.066819Z",
     "shell.execute_reply.started": "2024-05-25T01:06:55.004052Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# 0,1, 2, 3, be careful about the space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "870bf723-ebfa-4975-adad-53279ce21e0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T01:07:23.929980Z",
     "iopub.status.busy": "2024-05-25T01:07:23.929525Z",
     "iopub.status.idle": "2024-05-25T01:07:24.589668Z",
     "shell.execute_reply": "2024-05-25T01:07:24.588544Z",
     "shell.execute_reply.started": "2024-05-25T01:07:23.929938Z"
    }
   },
   "outputs": [],
   "source": [
    "from models.my_net_multi import myNet\n",
    "from models.losses import  ordinal_mse_loss\n",
    "from models.model_utils import generate_position_encode, trans_batch_multi, eval_model_multi \n",
    "from data_utils.eeg_load_sz import EEGDataSZ\n",
    "from data_utils import MyDataLoader\n",
    "from utils.misc import delta_time, load_pkl_folder2dict, save_pkl_dict2folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c0dd819-8b02-4c78-b283-633dd643a7a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T01:07:26.166126Z",
     "iopub.status.busy": "2024-05-25T01:07:26.165462Z",
     "iopub.status.idle": "2024-05-25T01:07:26.354133Z",
     "shell.execute_reply": "2024-05-25T01:07:26.352949Z",
     "shell.execute_reply.started": "2024-05-25T01:07:26.166082Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pkgs for pytorch (on Apr 3, 2023)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.functional import F\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "torch.set_default_device(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5711a766",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e86c794-a9ec-4239-8a21-e0369672fa9a",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e96609",
   "metadata": {},
   "source": [
    "## Model and training params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44d38d87-d50a-45e9-97ff-c2cde38024ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T01:10:52.418879Z",
     "iopub.status.busy": "2024-05-25T01:10:52.417879Z",
     "iopub.status.idle": "2024-05-25T01:10:52.950497Z",
     "shell.execute_reply": "2024-05-25T01:10:52.948980Z",
     "shell.execute_reply.started": "2024-05-25T01:10:52.418829Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if SAVED_MODEL is None:\n",
    "    config = edict()\n",
    "    config.nfeature = 19 # the dim of features at each time point\n",
    "    config.ndim = 256 # the output of the first FC layer\n",
    "    config.dropout = 0.5 # the dropout rate\n",
    "    config.n_layer = 2 # the number of self-attention layers\n",
    "    config.n_head = 8 # numher of heads for multi-head attention\n",
    "    config.is_mask = True # Use mask to make the attention causal\n",
    "    config.is_bias = True # Bias  for layernorm\n",
    "    config.block_size = 256 # the preset length of seq, \n",
    "    # if [1, 5], use X_t to predict X_{t+1}, X_{t+5}\n",
    "    config.move_steps = [1, 5, 10] # move steps\n",
    "    config.fs = 90\n",
    "    config.target_dim = 19 # TODO: the target dim can be deprecated in the future \n",
    "    config.k = 6 # discretize to 2^k levels\n",
    "    config.ncls = 2 # number of classes, 2 for my seizure data\n",
    "    # while include auxiliary loss or not \n",
    "    # the weight of the auxiliary loss is config.aux_loss_weight\n",
    "    config.aux_loss = True\n",
    "    config.aux_loss_weight = 1\n",
    "    \n",
    "    train_params = edict()\n",
    "    train_params.nepoch= 2\n",
    "    train_params.loss_out = 1\n",
    "    train_params.val_loss_out = 5\n",
    "    train_params.clip = 1 # \n",
    "    # lr step decay, if lr_step is 0, then no decay\n",
    "    # if '1epoch', then decay every epoch\n",
    "    train_params.lr_step = '1epoch'\n",
    "    train_params.lr = 1e-4 \n",
    "    train_params.lr_gamma = 0.1\n",
    "    train_params.lr_weight_decay = 0\n",
    "    # save the model \n",
    "    # if '1epoch', then save every epoch\n",
    "    train_params.save_interval = 5\n",
    "    # if 0, use all the training sz\n",
    "    train_params.ntrain_batch = 0# the number of batches for training\n",
    "    train_params.train_batch_size = 2 # the batch size for training\n",
    "    train_params.val_batch_size = 2 # the batch size for validation\n",
    "    train_params.test_batch_size = 2 # the batch size for test\n",
    "    train_params.train_01_ratio = 1 # the ratio of 0 and 1 in the training set\n",
    "    train_params.val_01_ratio = 2 # the ratio of 0 and 1 in the validation set\n",
    "    train_params.test_01_ratio = 2 # the ratio of 0 and 1 in the test set\n",
    "    train_params.train_size = 4\n",
    "    train_params.val_size = 4\n",
    "    train_params.test_size = 4 # if 0, use all the test set\n",
    "    train_params.seed = 0 # random seed\n",
    "\n",
    "\n",
    "    # data parameters\n",
    "    data_params = edict()\n",
    "    data_params.move_params=dict(winsize=config.block_size+np.max(config.move_steps), \n",
    "                     stepsize=config.block_size+np.max(config.move_steps), \n",
    "                     marginsize=None)\n",
    "    data_params.pre_params=dict(is_detrend=True, \n",
    "                    is_drop=True,\n",
    "                    target_fs=90, \n",
    "                    filter_limit=[1, 45], \n",
    "                    is_diff=False)\n",
    "    data_params.rm_params=dict(rm_len=50,\n",
    "                   keep_len=20)\n",
    "    data_params.subset = \"AR\"\n",
    "\n",
    "else:\n",
    "    saved_model_path = RES_ROOT/SAVED_MODEL\n",
    "    assert saved_model_path.exists(), \"No such model\"\n",
    "    saved_model = load_pkl_folder2dict(saved_model_path)\n",
    "    \n",
    "    config = saved_model.config\n",
    "    train_params = saved_model.train_params\n",
    "    data_params = saved_model.data_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9183517f",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7a74908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of data: train_bckg: 574065, train_sz: 28551 val_bckg: 199910, val_sz: 10461 test_bckg: 110870, test_sz: 8575\n"
     ]
    }
   ],
   "source": [
    "verbose = 1\n",
    "move_params = data_params.move_params\n",
    "pre_params = data_params.pre_params\n",
    "rm_params = data_params.rm_params\n",
    "subset = data_params.subset\n",
    "\n",
    "train_data_bckg = EEGDataSZ(\n",
    "    dataset=\"train\", \n",
    "    subset=subset,\n",
    "    label=\"bckg\", \n",
    "    discrete_k=config.k, \n",
    "    verbose=verbose, \n",
    "    move_params=move_params,\n",
    "    pre_params=pre_params,\n",
    "    rm_params=rm_params\n",
    "    )\n",
    "# to generate the cutoff of the background data for discretization\n",
    "train_data_bckg.get_dis_cutoffs();\n",
    "\n",
    "train_data_sz = EEGDataSZ(\n",
    "    dataset=\"train\", \n",
    "    subset=subset,\n",
    "    label=\"sz\", \n",
    "    discrete_k=config.k, \n",
    "    verbose=verbose, \n",
    "    move_params=move_params,\n",
    "    pre_params=pre_params,\n",
    "    rm_params=rm_params\n",
    "    )\n",
    "\n",
    "val_data_bckg = EEGDataSZ(\n",
    "    dataset=\"dev\", \n",
    "    subset=subset,\n",
    "    label=\"bckg\", \n",
    "    discrete_k=config.k, \n",
    "    verbose=verbose, \n",
    "    move_params=move_params,\n",
    "    pre_params=pre_params,\n",
    "    rm_params=rm_params\n",
    "    )\n",
    "\n",
    "val_data_sz = EEGDataSZ(\n",
    "    dataset=\"dev\", \n",
    "    subset=subset,\n",
    "    label=\"sz\", \n",
    "    discrete_k=config.k, \n",
    "    verbose=verbose, \n",
    "    move_params=move_params,\n",
    "    pre_params=pre_params,\n",
    "    rm_params=rm_params\n",
    "    )\n",
    "\n",
    "test_data_bckg = EEGDataSZ(\n",
    "    dataset=\"eval\", \n",
    "    subset=subset,\n",
    "    label=\"bckg\", \n",
    "    discrete_k=config.k, \n",
    "    verbose=verbose, \n",
    "    move_params=move_params,\n",
    "    pre_params=pre_params,\n",
    "    rm_params=rm_params\n",
    "    )\n",
    "\n",
    "test_data_sz = EEGDataSZ(\n",
    "    dataset=\"eval\", \n",
    "    subset=subset,\n",
    "    label=\"sz\", \n",
    "    discrete_k=config.k, \n",
    "    verbose=verbose, \n",
    "    move_params=move_params,\n",
    "    pre_params=pre_params,\n",
    "    rm_params=rm_params\n",
    "    )\n",
    "\n",
    "\n",
    "train_data_bckg_loader = MyDataLoader(train_data_bckg, \n",
    "                                      batch_size=train_params.train_batch_size*train_params.train_01_ratio, \n",
    "                                      shuffle=True,\n",
    "                                      seed=train_params.seed)\n",
    "train_data_sz_loader = MyDataLoader(train_data_sz, \n",
    "                                    batch_size=train_params.train_batch_size,\n",
    "                                    shuffle=True, \n",
    "                                    seed=train_params.seed)\n",
    "val_data_bckg_loader = MyDataLoader(val_data_bckg, \n",
    "                                      batch_size=train_params.val_batch_size*train_params.val_01_ratio,\n",
    "                                      shuffle=False, \n",
    "                                      seed=train_params.seed)\n",
    "val_data_sz_loader = MyDataLoader(val_data_sz, \n",
    "                                    batch_size=train_params.val_batch_size,\n",
    "                                    shuffle=False, \n",
    "                                    seed=train_params.seed)\n",
    "\n",
    "test_data_bckg_loader = MyDataLoader(test_data_bckg, \n",
    "                                      batch_size=train_params.test_batch_size*train_params.test_01_ratio,\n",
    "                                      shuffle=False, \n",
    "                                      seed=train_params.seed)\n",
    "test_data_sz_loader = MyDataLoader(test_data_sz, \n",
    "                                    batch_size=train_params.test_batch_size,\n",
    "                                    shuffle=False, \n",
    "                                    seed=train_params.seed)\n",
    "                                \n",
    "print(f\"Num of data: train_bckg: {len(train_data_bckg)}, train_sz: {len(train_data_sz)}\", \n",
    "      f\"val_bckg: {len(val_data_bckg)}, val_sz: {len(val_data_sz)}\", \n",
    "      f\"test_bckg: {len(test_data_bckg)}, test_sz: {len(test_data_sz)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6269c13c",
   "metadata": {},
   "source": [
    "## Prepare training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ed6692b-f81b-4023-a3a5-a87e1b9a6913",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T01:10:59.741857Z",
     "iopub.status.busy": "2024-05-25T01:10:59.740911Z",
     "iopub.status.idle": "2024-05-25T01:10:59.793529Z",
     "shell.execute_reply": "2024-05-25T01:10:59.793115Z",
     "shell.execute_reply.started": "2024-05-25T01:10:59.741809Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 1.7324M\n"
     ]
    }
   ],
   "source": [
    "pos_enc = generate_position_encode(config.block_size, config.nfeature).unsqueeze(0)\n",
    "loss_fn1 = ordinal_mse_loss\n",
    "# logSoftmax + NLLLoss = CrossEntropyLoss\n",
    "loss_fn2 = nn.NLLLoss() \n",
    "\n",
    "if SAVED_MODEL is None:\n",
    "    net = myNet(config)\n",
    "else:\n",
    "    net = saved_model.model\n",
    "if torch.cuda.is_available():\n",
    "    net = net.cuda()\n",
    "optimizer = torch.optim.Adam(net.parameters(), \n",
    "                             lr=train_params.lr,\n",
    "                             weight_decay=train_params.lr_weight_decay)\n",
    "scheduler = ExponentialLR(optimizer, \n",
    "                          gamma=train_params.lr_gamma);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923f4998",
   "metadata": {},
   "source": [
    "## training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61b5795f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "{'clip': 1,\n",
      " 'loss_out': 1,\n",
      " 'lr': 0.0001,\n",
      " 'lr_gamma': 0.1,\n",
      " 'lr_step': '1epoch',\n",
      " 'lr_weight_decay': 0,\n",
      " 'nepoch': 2,\n",
      " 'ntrain_batch': 0,\n",
      " 'save_interval': 5,\n",
      " 'seed': 0,\n",
      " 'test_01_ratio': 2,\n",
      " 'test_batch_size': 2,\n",
      " 'test_size': 4,\n",
      " 'train_01_ratio': 1,\n",
      " 'train_batch_size': 2,\n",
      " 'train_size': 4,\n",
      " 'val_01_ratio': 2,\n",
      " 'val_batch_size': 2,\n",
      " 'val_loss_out': 5,\n",
      " 'val_size': 4}\n",
      "{'move_params': {'marginsize': None, 'stepsize': 266, 'winsize': 266},\n",
      " 'pre_params': {'filter_limit': [1, 45],\n",
      "                'is_detrend': True,\n",
      "                'is_diff': False,\n",
      "                'is_drop': True,\n",
      "                'target_fs': 90},\n",
      " 'rm_params': {'keep_len': 20, 'rm_len': 50},\n",
      " 'subset': 'AR'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Start training\")\n",
    "pprint(train_params)\n",
    "pprint(data_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd03d3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _save_model():\n",
    "    model_res = edict()\n",
    "    model_res.config = config\n",
    "    model_res.loss_fns = [loss_fn1, loss_fn2]\n",
    "    model_res.loss_save = loss_save\n",
    "    model_res.train_params = train_params\n",
    "    model_res.data_params = data_params\n",
    "    \n",
    "    if SAVED_MODEL is None:\n",
    "        cur_model_name = f\"{MODEL_NAME}_epoch{iep+1}_iter{ix+1}\"\n",
    "    else:\n",
    "        cur_model_name = f\"{MODEL_NAME}_epoch{iep+1}_iter{ix+1}_w_{SAVED_MODEL}\"\n",
    "\n",
    "    save_pkl_dict2folder(RES_ROOT/cur_model_name, model_res, is_force=True)\n",
    "    # save model     \n",
    "    torch.save(net.state_dict(), RES_ROOT/cur_model_name/\"model.pth\")\n",
    "    torch.save(optimizer.state_dict(), RES_ROOT/cur_model_name/\"optimizer.pth\")\n",
    "    torch.save(scheduler.state_dict(), RES_ROOT/cur_model_name/\"scheduler.pth\")\n",
    "    # copy class file \n",
    "    shutil.copy(MODEL_ROOT/MODEL_CLASS, RES_ROOT/cur_model_name/\"model_class.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6519005d-6a00-4f5c-9276-f025c00453b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T01:11:12.468981Z",
     "iopub.status.busy": "2024-05-25T01:11:12.468103Z",
     "iopub.status.idle": "2024-05-25T01:11:40.789797Z",
     "shell.execute_reply": "2024-05-25T01:11:40.789097Z",
     "shell.execute_reply.started": "2024-05-25T01:11:12.468934Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current lr is [0.0001].\n",
      "training: True\n",
      "At iter 1/14275, epoch 1,aux_loss: 0.212, cls_loss: 1.202, loss: 1.413, auc: 0.688, the time used is 4.384s.\n",
      "training: False\n",
      "training: True\n",
      "At iter 2/14275, epoch 1,aux_loss: 0.244, cls_loss: 6.390, loss: 6.634, auc: 0.672, the time used is 3.242s.\n",
      "training: False\n",
      "training: True\n",
      "At iter 3/14275, epoch 1,aux_loss: 0.282, cls_loss: 3.537, loss: 3.819, auc: 0.656, the time used is 3.294s.\n",
      "training: False\n",
      "training: True\n",
      "At iter 4/14275, epoch 1,aux_loss: 0.268, cls_loss: 2.967, loss: 3.236, auc: 0.641, the time used is 3.446s.\n",
      "training: False\n",
      "training: True\n",
      "At iter 5/14275, epoch 1,aux_loss: 0.242, cls_loss: 5.510, loss: 5.752, auc: 0.625, the time used is 3.255s.\n",
      "==================================================\n",
      "Val results: At iter 5/14275, epoch 1,aux_loss: 0.248. cls_loss: 3.942. auc: 0.469. \n",
      "==================================================\n",
      "**************************************************\n",
      "Test results: At iter 5/14275, epoch 1,aux_loss: 0.226. cls_loss: 4.484. auc: 0.328. \n",
      "**************************************************\n",
      "Save to /data/rajlab1/user_data/jin/MyResearch/EEG-sz-det_dev/notebooks/../mypkg/../results/test_epoch1_iter5/config.pkl\n",
      "Save to /data/rajlab1/user_data/jin/MyResearch/EEG-sz-det_dev/notebooks/../mypkg/../results/test_epoch1_iter5/loss_fns.pkl\n",
      "Save to /data/rajlab1/user_data/jin/MyResearch/EEG-sz-det_dev/notebooks/../mypkg/../results/test_epoch1_iter5/loss_save.pkl\n",
      "Save to /data/rajlab1/user_data/jin/MyResearch/EEG-sz-det_dev/notebooks/../mypkg/../results/test_epoch1_iter5/train_params.pkl\n",
      "Save to /data/rajlab1/user_data/jin/MyResearch/EEG-sz-det_dev/notebooks/../mypkg/../results/test_epoch1_iter5/data_params.pkl\n",
      "training: False\n",
      "training: True\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 80\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ix \u001b[38;5;241m%\u001b[39m train_params\u001b[38;5;241m.\u001b[39mloss_out \u001b[38;5;241m==\u001b[39m (train_params\u001b[38;5;241m.\u001b[39mloss_out\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     79\u001b[0m     loss_save[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mniter_auc\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(total_iter)\n\u001b[0;32m---> 80\u001b[0m     curlosses \u001b[38;5;241m=\u001b[39m \u001b[43meval_model_multi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mdata_loader_sz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_data_sz_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mdata_loader_bckg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_data_bckg_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mn_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ky \u001b[38;5;129;01min\u001b[39;00m curlosses\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m     86\u001b[0m         loss_save[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m][ky]\u001b[38;5;241m.\u001b[39mappend(curlosses[ky])\n",
      "File \u001b[0;32m/data/rajlab1/user_data/jin/MyResearch/EEG-sz-det_dev/notebooks/../mypkg/models/model_utils.py:233\u001b[0m, in \u001b[0;36meval_model_multi\u001b[0;34m(trained_model, data_loader_sz, data_loader_bckg, cls_loss_fn, aux_loss_fn, n_batch, random, verbose)\u001b[0m\n\u001b[1;32m    231\u001b[0m ress \u001b[38;5;241m=\u001b[39m ddict(\u001b[38;5;28mlist\u001b[39m)\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m idxs:\n\u001b[0;32m--> 233\u001b[0m     batch_sz, batch_bckg \u001b[38;5;241m=\u001b[39m data_loader_sz(idx), \u001b[43mdata_loader_bckg\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m;\n\u001b[1;32m    234\u001b[0m     trans_res \u001b[38;5;241m=\u001b[39m trans_batch_multi(batch_sz, batch_bckg, config\u001b[38;5;241m=\u001b[39mtrained_model\u001b[38;5;241m.\u001b[39mconfig,\n\u001b[1;32m    235\u001b[0m                                        shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    236\u001b[0m     X_org \u001b[38;5;241m=\u001b[39m trans_res[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/data/rajlab1/user_data/jin/MyResearch/EEG-sz-det_dev/notebooks/../mypkg/data_utils/utils.py:151\u001b[0m, in \u001b[0;36mMyDataLoader.__call__\u001b[0;34m(self, ix)\u001b[0m\n\u001b[1;32m    149\u001b[0m batch_dis, batch_raw \u001b[38;5;241m=\u001b[39m [], []\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_idxs[low:up]:\n\u001b[0;32m--> 151\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    152\u001b[0m     batch_dis\u001b[38;5;241m.\u001b[39mappend(batch[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    153\u001b[0m     batch_raw\u001b[38;5;241m.\u001b[39mappend(batch[\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m/data/rajlab1/user_data/jin/MyResearch/EEG-sz-det_dev/notebooks/../mypkg/data_utils/eeg_load_sz.py:194\u001b[0m, in \u001b[0;36mEEGDataSZ.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    193\u001b[0m     idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__len__\u001b[39m() \u001b[38;5;241m+\u001b[39m idx\n\u001b[0;32m--> 194\u001b[0m num_sps_persub \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39msum(idx) \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_sps_persub]\n\u001b[1;32m    195\u001b[0m num_cumsum \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcumsum(num_sps_persub)\n\u001b[1;32m    196\u001b[0m num_cumsum \u001b[38;5;241m=\u001b[39m num_cumsum\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[0;32m/data/rajlab1/user_data/jin/MyResearch/EEG-sz-det_dev/notebooks/../mypkg/data_utils/eeg_load_sz.py:194\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    193\u001b[0m     idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__len__\u001b[39m() \u001b[38;5;241m+\u001b[39m idx\n\u001b[0;32m--> 194\u001b[0m num_sps_persub \u001b[38;5;241m=\u001b[39m [\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_sps_persub]\n\u001b[1;32m    195\u001b[0m num_cumsum \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcumsum(num_sps_persub)\n\u001b[1;32m    196\u001b[0m num_cumsum \u001b[38;5;241m=\u001b[39m num_cumsum\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[0;32m~/jin/conda/envs/eeg-sz-det/lib/python3.9/site-packages/numpy/core/fromnumeric.py:2313\u001b[0m, in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2310\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[1;32m   2311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[0;32m-> 2313\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2314\u001b[0m \u001b[43m                      \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jin/conda/envs/eeg-sz-det/lib/python3.9/site-packages/numpy/core/fromnumeric.py:88\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     86\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training\n",
    "if SAVED_MODEL is None:\n",
    "    loss_save = {}\n",
    "    #loss_save.train_niter = []\n",
    "    #loss_save.val_niter = []\n",
    "    #loss_save.test_niter = []\n",
    "    loss_save[\"train\"] = ddict(list)\n",
    "    loss_save[\"val\"] = ddict(list)\n",
    "    loss_save[\"test\"] = ddict(list)\n",
    "else:\n",
    "    loss_save = saved_model.loss_save\n",
    "\n",
    "if train_params.ntrain_batch ==0:\n",
    "    ntrain_batch = len(train_data_sz_loader)\n",
    "else: \n",
    "    ntrain_batch = train_params.ntrain_batch\n",
    "if ntrain_batch > len(train_data_sz_loader):\n",
    "    ntrain_batch = len(train_data_sz_loader)\n",
    "    print(f\"The number of training batches is larger than the number of training data, use all the training data to train, i.e., ntrain_batch={ntrain_batch}.\")\n",
    "if isinstance(train_params.lr_step, str):\n",
    "    lr_step = int(ntrain_batch * float(train_params.lr_step[:-5]))\n",
    "else:\n",
    "    lr_step = train_params.lr_step\n",
    "if isinstance(train_params.save_interval, str):\n",
    "    save_interval = int(ntrain_batch * float(train_params.save_interval[:-5]))\n",
    "else:\n",
    "    save_interval = train_params.save_interval\n",
    "\n",
    "\n",
    "t0 = time.time()\n",
    "total_iter = 0\n",
    "for iep in range(train_params.nepoch):\n",
    "    net.cuda()\n",
    "    print(f\"The current lr is {scheduler.get_last_lr()}.\")\n",
    "    for ix in range(ntrain_batch):\n",
    "        net.train()\n",
    "        batch_sz = train_data_sz_loader(ix)\n",
    "        batch_bckg = train_data_bckg_loader(ix)\n",
    "        trans_res  = trans_batch_multi(batch_sz=batch_sz, batch_bckg=batch_bckg, \n",
    "                                              config=config,\n",
    "                                              shuffle=True)\n",
    "        X_org = trans_res[0]\n",
    "        Y_diss = trans_res[1:-1]\n",
    "        szlabels = trans_res[-1]\n",
    "        X_org_wpos = X_org + pos_enc\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if config.aux_loss:\n",
    "            probss_aux, log_probs_cls = net(X_org_wpos)\n",
    "            loss1 = 0\n",
    "            for Y_dis, probs_aux in zip(Y_diss, probss_aux):\n",
    "                loss1p = loss_fn1(probs_aux, Y_dis, num_cls=2**config.k)\n",
    "                loss1 += loss1p\n",
    "            loss1 = loss1/len(Y_diss)\n",
    "            loss2 = loss_fn2(log_probs_cls, szlabels)\n",
    "            loss = config.aux_loss_weight*loss1 + loss2\n",
    "        \n",
    "            # record the loss\n",
    "            loss_save[\"train\"][\"aux_loss\"].append(loss1.item())\n",
    "            loss_save[\"train\"][\"cls_loss\"].append(loss2.item())\n",
    "            loss_save[\"train\"][\"loss\"].append(loss.item())\n",
    "        else:\n",
    "            log_probs_cls = net(X_org_wpos)\n",
    "            loss = loss_fn2(log_probs_cls, szlabels)\n",
    "            loss_save[\"train\"][\"cls_loss\"].append(loss.item())\n",
    "            loss_save[\"train\"][\"loss\"].append(loss.item())\n",
    "        loss_save[\"train\"][\"niter\"].append(total_iter)\n",
    "        \n",
    "        print(\"training:\", net.training)\n",
    "        # Perform backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(net.parameters(), train_params.clip)\n",
    "        # Perform optimization\n",
    "        optimizer.step()\n",
    "        \n",
    "        if ix % train_params.loss_out == (train_params.loss_out-1):\n",
    "            loss_save[\"train\"][\"niter_auc\"].append(total_iter)\n",
    "            curlosses = eval_model_multi(net, \n",
    "                                   data_loader_sz=train_data_sz_loader, \n",
    "                                   data_loader_bckg=train_data_bckg_loader,\n",
    "                                   n_batch=train_params.train_size, random=True)\n",
    "                            \n",
    "            for ky in curlosses.keys():\n",
    "                loss_save[\"train\"][ky].append(curlosses[ky])\n",
    "            loss_msg = f\"At iter {ix+1}/{ntrain_batch}, epoch {iep+1},\" \n",
    "            for k, v in loss_save[\"train\"].items():\n",
    "                if k in [\"probs_sz\", \"labs_sz\", \"niter\", \"niter_auc\"]:\n",
    "                    continue\n",
    "                elif k in [\"auc\"]:\n",
    "                    loss_msg += f\"{k}: {v[-1]:.3f}, \"\n",
    "                else:\n",
    "                    loss_msg += f\"{k}: {np.mean(v[-train_params.loss_out:]):.3f}, \"\n",
    "            loss_msg += f\"the time used is {delta_time(t0):.3f}s.\"\n",
    "            print(loss_msg)\n",
    "            t0 = time.time()\n",
    "            \n",
    "        if ix % train_params.val_loss_out == (train_params.val_loss_out-1):\n",
    "            loss_save[\"val\"][\"niter\"].append(total_iter)\n",
    "            curlosses = eval_model_multi(net, \n",
    "                                   data_loader_sz=val_data_sz_loader, \n",
    "                                   data_loader_bckg=val_data_bckg_loader, \n",
    "                                   cls_loss_fn=loss_fn2,\n",
    "                                   aux_loss_fn=loss_fn1 if config.aux_loss else None,\n",
    "                                   n_batch=train_params.val_size, random=True)\n",
    "            for ky in curlosses.keys():\n",
    "                loss_save[\"val\"][ky].append(curlosses[ky])\n",
    "            print(\"=\"*50)\n",
    "            loss_msg = f\"At iter {ix+1}/{ntrain_batch}, epoch {iep+1},\" \n",
    "            for k, v in loss_save[\"val\"].items():\n",
    "                if k in [\"probs_sz\", \"labs_sz\", \"niter\"]:\n",
    "                    continue\n",
    "                loss_msg += f\"{k}: {np.mean(v[-1]):.3f}. \"\n",
    "            print(\"Val results: \" + loss_msg)\n",
    "            print(\"=\"*50)\n",
    "            t0 = time.time()\n",
    "        \n",
    "        if total_iter % lr_step == (lr_step-1):\n",
    "            scheduler.step()\n",
    "\n",
    "        if total_iter % save_interval == (save_interval-1):\n",
    "            # when saving model, test the model on the test data\n",
    "            loss_save[\"test\"][\"niter\"].append(total_iter)\n",
    "\n",
    "            curlosses = eval_model_multi(net, \n",
    "                                   data_loader_sz=test_data_sz_loader, \n",
    "                                   data_loader_bckg=test_data_bckg_loader, \n",
    "                                   cls_loss_fn=loss_fn2,\n",
    "                                   aux_loss_fn=loss_fn1 if config.aux_loss else None,\n",
    "                                   n_batch=train_params.test_size, \n",
    "                                   random=False)\n",
    "            for ky in curlosses.keys():\n",
    "                loss_save[\"test\"][ky].append(curlosses[ky])\n",
    "            print(\"*\"*50)\n",
    "            loss_msg = f\"At iter {ix+1}/{ntrain_batch}, epoch {iep+1},\" \n",
    "            for k, v in loss_save[\"test\"].items():\n",
    "                if k in [\"probs_sz\", \"labs_sz\", \"niter\"]:\n",
    "                    continue\n",
    "                loss_msg += f\"{k}: {np.mean(v[-1]):.3f}. \"\n",
    "            print(\"Test results: \" + loss_msg)\n",
    "            print(\"*\"*50)\n",
    "\n",
    "            _save_model()\n",
    "            t0 = time.time()\n",
    "\n",
    "    \n",
    "            # save the model \n",
    "        total_iter += 1\n",
    "        print(\"training:\", net.training)\n",
    "    _save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18a7272",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SSH titan.radiology.ucsf.edu titan-EEG",
   "language": "",
   "name": "rik_ssh_titan_radiology_ucsf_edu_titaneeg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
