{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8e33dd9",
   "metadata": {},
   "source": [
    "This notebook is to train the model to reconstruct the input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c181065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my_net_selflearning.py'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME = \"test\"\n",
    "SAVED_MODEL = None\n",
    "MODEL_CLASS = \"my_net_selflearning.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41410529",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from jin_utils import get_mypkg_path\n",
    "pkgpath = get_mypkg_path()\n",
    "sys.path.append(pkgpath)\n",
    "from constants import RES_ROOT, DATA_ROOT, MIDRES_ROOT, FIG_ROOT, MODEL_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd0b2ec3-922a-40d5-ad69-4701aa9ad1fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T03:09:20.463961Z",
     "iopub.status.busy": "2023-05-21T03:09:20.462969Z",
     "iopub.status.idle": "2023-05-21T03:09:24.601700Z",
     "shell.execute_reply": "2023-05-21T03:09:24.600516Z",
     "shell.execute_reply.started": "2023-05-21T03:09:20.463913Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from easydict import EasyDict as edict\n",
    "import time\n",
    "# copy file\n",
    "import shutil\n",
    "from pprint import pprint\n",
    "from collections import defaultdict as ddict\n",
    "\n",
    "plt.style.use(FIG_ROOT/\"base.mplstyle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c03acb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# 0,1, 2, 3, be careful about the space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "870bf723-ebfa-4975-adad-53279ce21e0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T03:09:39.021287Z",
     "iopub.status.busy": "2023-05-21T03:09:39.020294Z",
     "iopub.status.idle": "2023-05-21T03:09:39.048940Z",
     "shell.execute_reply": "2023-05-21T03:09:39.047714Z",
     "shell.execute_reply.started": "2023-05-21T03:09:39.021240Z"
    }
   },
   "outputs": [],
   "source": [
    "from models.model_utils import generate_position_encode, eval_model_selflearning\n",
    "from models.my_net_selflearning import myNet\n",
    "from data_utils.eeg_load import EEGData\n",
    "from data_utils.utils import MyDataLoader\n",
    "from jin_utils import  load_pkl_folder2dict, save_pkl_dict2folder\n",
    "from utils.misc import delta_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c0dd819-8b02-4c78-b283-633dd643a7a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T03:09:39.051157Z",
     "iopub.status.busy": "2023-05-21T03:09:39.050390Z",
     "iopub.status.idle": "2023-05-21T03:09:39.059491Z",
     "shell.execute_reply": "2023-05-21T03:09:39.058266Z",
     "shell.execute_reply.started": "2023-05-21T03:09:39.051113Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.functional import F\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "\n",
    "df_dtype = torch.float32\n",
    "\n",
    "torch.set_default_dtype(df_dtype)\n",
    "if torch.cuda.is_available():\n",
    "    df_device = torch.device(\"cuda\")\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "else:\n",
    "    df_device = torch.device(\"cpu\")\n",
    "torch.set_default_device(df_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e86c794-a9ec-4239-8a21-e0369672fa9a",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44d38d87-d50a-45e9-97ff-c2cde38024ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T03:09:43.852406Z",
     "iopub.status.busy": "2023-05-21T03:09:43.851477Z",
     "iopub.status.idle": "2023-05-21T03:09:43.862761Z",
     "shell.execute_reply": "2023-05-21T03:09:43.861528Z",
     "shell.execute_reply.started": "2023-05-21T03:09:43.852360Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if SAVED_MODEL is None:\n",
    "    config = edict()\n",
    "    nroi = 19\n",
    "    # the dim of features at each time point, not used in this net\n",
    "    config.nfeature = nroi \n",
    "    config.ndim0 = 128 # the number of queries for the first FC layer\n",
    "    config.ndim = 256 # the output of the first FC layer\n",
    "    config.dropout = 0.5 # the dropout rate\n",
    "    config.n_layer = 2 # the number of self-attention layers\n",
    "    config.n_head = 8 # numher of heads for multi-head attention\n",
    "    config.is_mask = True # Use mask to make the attention causal\n",
    "    config.is_bias = True # Bias  for layernorm\n",
    "    config.block_size = 256 # the preset length of seq, \n",
    "    config.fs = 90\n",
    "    config.target_dim = nroi # the target dim \n",
    "\n",
    "    train_params = edict()\n",
    "    train_params.nepoch= 2\n",
    "    train_params.loss_out = 10\n",
    "    train_params.val_loss_out = 100\n",
    "    train_params.clip = 1 # \n",
    "    # lr step decay, if lr_step is 0, then no decay\n",
    "    # if '1epoch', then decay every epoch\n",
    "    train_params.lr_step = '1epoch'\n",
    "    train_params.lr = 1e-4 \n",
    "    train_params.lr_gamma = 0.1\n",
    "    train_params.lr_weight_decay = 0\n",
    "    # save the model \n",
    "    # if '1epoch', then save every epoch\n",
    "    train_params.save_interval = 10000\n",
    "\n",
    "    train_params.ntrain_batch = 0 # the number of batches for training\n",
    "    train_params.train_batch_size = 64 # the batch size for training\n",
    "    train_params.val_batch_size = 64 # the batch size for validation\n",
    "    train_params.train_size = 4\n",
    "    train_params.val_size = 4\n",
    "    train_params.seed = 0 # random seed\n",
    "\n",
    "    # data parameters\n",
    "    data_params = edict()\n",
    "    data_params.move_params=dict(winsize=config.block_size,\n",
    "                     stepsize=config.block_size,\n",
    "                     marginsize=None)\n",
    "    data_params.pre_params=dict(is_detrend=True, \n",
    "                    is_drop=True,\n",
    "                    target_fs=90, \n",
    "                    filter_limit=[1, 45], \n",
    "                    is_diff=False)\n",
    "    data_params.rm_params=dict(rm_len=50, keep_len=20)\n",
    "    data_params.subset = \"ALL\"\n",
    "else:\n",
    "    saved_model_path = RES_ROOT/SAVED_MODEL\n",
    "    assert saved_model_path.exists(), \"No such model\"\n",
    "    saved_model = load_pkl_folder2dict(saved_model_path)\n",
    "    \n",
    "    config = saved_model.config\n",
    "    train_params = saved_model.train_params\n",
    "    data_params = saved_model.data_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32453bd4-d9d9-4b3d-85bc-4b132e7e8a93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T03:09:44.532021Z",
     "iopub.status.busy": "2023-05-21T03:09:44.531506Z",
     "iopub.status.idle": "2023-05-21T03:09:44.720685Z",
     "shell.execute_reply": "2023-05-21T03:09:44.720246Z",
     "shell.execute_reply.started": "2023-05-21T03:09:44.531978Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14900 2057\n"
     ]
    }
   ],
   "source": [
    "move_params = data_params.move_params\n",
    "pre_params = data_params.pre_params\n",
    "rm_params = data_params.rm_params\n",
    "subset = data_params.subset\n",
    "train_data = EEGData(dataset=\"train\", \n",
    "                     subset=subset,\n",
    "                     move_params=move_params,\n",
    "                     pre_params=pre_params,\n",
    "                     )\n",
    "val_data = EEGData(dataset=\"eval\", \n",
    "                     subset=subset,\n",
    "                     move_params=move_params,\n",
    "                     pre_params=pre_params,\n",
    "                     )\n",
    "train_data_loader = MyDataLoader(train_data, batch_size=train_params.train_batch_size, shuffle=True)\n",
    "val_data_loader = MyDataLoader(val_data, batch_size=train_params.val_batch_size, shuffle=False)\n",
    "print(len(train_data_loader), len(val_data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "378d939b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 1.6508M\n"
     ]
    }
   ],
   "source": [
    "pos_enc = generate_position_encode(config.block_size, config.nfeature).unsqueeze(0)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "if SAVED_MODEL is None:\n",
    "    net = myNet(config)\n",
    "else:\n",
    "    net = saved_model.model.to(df_device)\n",
    "optimizer = torch.optim.Adam(net.parameters(), \n",
    "                             lr=train_params.lr,\n",
    "                             weight_decay=train_params.lr_weight_decay)\n",
    "scheduler = ExponentialLR(optimizer, \n",
    "                          gamma=train_params.lr_gamma);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8617c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _save_model():\n",
    "    model_res = edict()\n",
    "    model_res.config = config\n",
    "    model_res.loss_fns = loss_fn\n",
    "    model_res.loss_save = loss_save\n",
    "    model_res.train_params = train_params\n",
    "    model_res.data_params = data_params\n",
    "    \n",
    "    if SAVED_MODEL is None:\n",
    "        cur_model_name = f\"{MODEL_NAME}_epoch{iep+1}_iter{ix+1}\"\n",
    "    else:\n",
    "        cur_model_name = f\"{MODEL_NAME}_epoch{iep+1}_iter{ix+1}_w_{SAVED_MODEL}\"\n",
    "\n",
    "    save_pkl_dict2folder(RES_ROOT/cur_model_name, model_res, is_force=True)\n",
    "    # save model     \n",
    "    torch.save(net.state_dict(), RES_ROOT/cur_model_name/\"model.pth\")\n",
    "    torch.save(optimizer.state_dict(), RES_ROOT/cur_model_name/\"optimizer.pth\")\n",
    "    torch.save(scheduler.state_dict(), RES_ROOT/cur_model_name/\"scheduler.pth\")\n",
    "    # copy class file \n",
    "    shutil.copy(MODEL_ROOT/MODEL_CLASS, RES_ROOT/cur_model_name/\"model_class.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "897e3bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "{'clip': 1,\n",
      " 'loss_out': 10,\n",
      " 'lr': 0.0001,\n",
      " 'lr_gamma': 0.1,\n",
      " 'lr_step': '1epoch',\n",
      " 'lr_weight_decay': 0,\n",
      " 'nepoch': 2,\n",
      " 'ntrain_batch': 0,\n",
      " 'save_interval': 10000,\n",
      " 'seed': 0,\n",
      " 'train_batch_size': 64,\n",
      " 'train_size': 4,\n",
      " 'val_batch_size': 64,\n",
      " 'val_loss_out': 100,\n",
      " 'val_size': 4}\n",
      "{'move_params': {'marginsize': None, 'stepsize': 256, 'winsize': 256},\n",
      " 'pre_params': {'filter_limit': [1, 45],\n",
      "                'is_detrend': True,\n",
      "                'is_diff': False,\n",
      "                'is_drop': True,\n",
      "                'target_fs': 90},\n",
      " 'rm_params': {'keep_len': 20, 'rm_len': 50},\n",
      " 'subset': 'AR'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Start training\")\n",
    "pprint(train_params)\n",
    "pprint(data_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e761e78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current lr is [0.0001].\n",
      "At iter 9, the train loss is 0.582, the time used is 162.527s.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ix \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(ntrain_batch):\n\u001b[1;32m     25\u001b[0m     net\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 26\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_data_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     batch \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mto(df_dtype)\n\u001b[1;32m     29\u001b[0m     batch_wpos \u001b[38;5;241m=\u001b[39m batch \u001b[38;5;241m+\u001b[39m pos_enc\n",
      "File \u001b[0;32m/mnt/nfs/rad/data/jianglab1/jin/MyResearch/EEG-sz-det_dev/mypkg/data_utils/utils.py:162\u001b[0m, in \u001b[0;36mMyDataLoader.__call__\u001b[0;34m(self, ix)\u001b[0m\n\u001b[1;32m    160\u001b[0m batch \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_idxs[low:up]:\n\u001b[0;32m--> 162\u001b[0m     batch\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m    163\u001b[0m batch \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(batch)\n\u001b[1;32m    164\u001b[0m batch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(batch)\n",
      "File \u001b[0;32m/mnt/nfs/rad/data/jianglab1/jin/MyResearch/EEG-sz-det_dev/mypkg/data_utils/eeg_load.py:276\u001b[0m, in \u001b[0;36mEEGData.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;66;03m# remove the first and last pts\u001b[39;00m\n\u001b[1;32m    275\u001b[0m data \u001b[38;5;241m=\u001b[39m data[:, \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_params\u001b[38;5;241m.\u001b[39mtarget_fs\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrm_params\u001b[38;5;241m.\u001b[39mrm_len):\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_params\u001b[38;5;241m.\u001b[39mtarget_fs\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrm_params\u001b[38;5;241m.\u001b[39mrm_len)]\n\u001b[0;32m--> 276\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_robust_EEG_rescale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpre_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_fct\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loc_idx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m     _, low_idxs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_len2num(np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_dur\u001b[39m\u001b[38;5;124m\"\u001b[39m])[sub_idx] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_params\u001b[38;5;241m.\u001b[39mtarget_fs, \n\u001b[1;32m    280\u001b[0m                                               \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmove_params\u001b[38;5;241m.\u001b[39mwinsize, \n\u001b[1;32m    281\u001b[0m                                               \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmove_params\u001b[38;5;241m.\u001b[39mstepsize, \n\u001b[1;32m    282\u001b[0m                                               \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmove_params\u001b[38;5;241m.\u001b[39mmarginsize)\n",
      "File \u001b[0;32m/mnt/nfs/rad/data/jianglab1/jin/MyResearch/EEG-sz-det_dev/mypkg/data_utils/eeg_load.py:180\u001b[0m, in \u001b[0;36mEEGData._robust_EEG_rescale\u001b[0;34m(self, data, data_max)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"rescale data robustly.\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data_max \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 180\u001b[0m     data_max \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.95\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# to remove the effet of outliers\u001b[39;00m\n\u001b[1;32m    181\u001b[0m data_rescaled \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m/\u001b[39mdata_max\n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m#data_min = -data_max\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;66;03m#data_minmax = 2*(data-data_min)/(data_max-data_min) - 1;\u001b[39;00m\n",
      "File \u001b[0;32m~/jin/conda/envs/eeg-sz-det/lib/python3.9/site-packages/numpy/lib/function_base.py:4543\u001b[0m, in \u001b[0;36mquantile\u001b[0;34m(a, q, axis, out, overwrite_input, method, keepdims, interpolation)\u001b[0m\n\u001b[1;32m   4541\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _quantile_is_valid(q):\n\u001b[1;32m   4542\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuantiles must be in the range [0, 1]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 4543\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_quantile_unchecked\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4544\u001b[0m \u001b[43m    \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jin/conda/envs/eeg-sz-det/lib/python3.9/site-packages/numpy/lib/function_base.py:4555\u001b[0m, in \u001b[0;36m_quantile_unchecked\u001b[0;34m(a, q, axis, out, overwrite_input, method, keepdims)\u001b[0m\n\u001b[1;32m   4547\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_quantile_unchecked\u001b[39m(a,\n\u001b[1;32m   4548\u001b[0m                         q,\n\u001b[1;32m   4549\u001b[0m                         axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4552\u001b[0m                         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   4553\u001b[0m                         keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   4554\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Assumes that q is in [0, 1], and is an ndarray\"\"\"\u001b[39;00m\n\u001b[0;32m-> 4555\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ureduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4556\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_quantile_ureduce_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4557\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4558\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4559\u001b[0m \u001b[43m                    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4560\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4561\u001b[0m \u001b[43m                    \u001b[49m\u001b[43moverwrite_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4562\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jin/conda/envs/eeg-sz-det/lib/python3.9/site-packages/numpy/lib/function_base.py:3823\u001b[0m, in \u001b[0;36m_ureduce\u001b[0;34m(a, func, keepdims, **kwargs)\u001b[0m\n\u001b[1;32m   3820\u001b[0m             index_out \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, ) \u001b[38;5;241m*\u001b[39m nd\n\u001b[1;32m   3821\u001b[0m             kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m out[(\u001b[38;5;28mEllipsis\u001b[39m, ) \u001b[38;5;241m+\u001b[39m index_out]\n\u001b[0;32m-> 3823\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3825\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3826\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/jin/conda/envs/eeg-sz-det/lib/python3.9/site-packages/numpy/lib/function_base.py:4722\u001b[0m, in \u001b[0;36m_quantile_ureduce_func\u001b[0;34m(a, q, axis, out, overwrite_input, method)\u001b[0m\n\u001b[1;32m   4720\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4721\u001b[0m         arr \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m-> 4722\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43m_quantile\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4723\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mquantiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4724\u001b[0m \u001b[43m                   \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4725\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4726\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4727\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/jin/conda/envs/eeg-sz-det/lib/python3.9/site-packages/numpy/lib/function_base.py:4824\u001b[0m, in \u001b[0;36m_quantile\u001b[0;34m(arr, quantiles, axis, method, out)\u001b[0m\n\u001b[1;32m   4820\u001b[0m previous_indexes, next_indexes \u001b[38;5;241m=\u001b[39m _get_indexes(arr,\n\u001b[1;32m   4821\u001b[0m                                               virtual_indexes,\n\u001b[1;32m   4822\u001b[0m                                               values_count)\n\u001b[1;32m   4823\u001b[0m \u001b[38;5;66;03m# --- Sorting\u001b[39;00m\n\u001b[0;32m-> 4824\u001b[0m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartition\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4825\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4826\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mprevious_indexes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4827\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mnext_indexes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4828\u001b[0m \u001b[43m                              \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4829\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4830\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m supports_nans:\n\u001b[1;32m   4831\u001b[0m     slices_having_nans \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39misnan(arr[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ntrain_batch = len(train_data_loader)\n",
    "# training\n",
    "if SAVED_MODEL is None:\n",
    "    loss_save = {}\n",
    "    loss_save[\"train\"] = ddict(list)\n",
    "    loss_save[\"val\"] = ddict(list)\n",
    "else:\n",
    "    loss_save = saved_model.loss_save\n",
    "\n",
    "if isinstance(train_params.lr_step, str):\n",
    "    lr_step = int(ntrain_batch * float(train_params.lr_step[:-5]))\n",
    "else:\n",
    "    lr_step = train_params.lr_step\n",
    "if isinstance(train_params.save_interval, str):\n",
    "    save_interval = int(ntrain_batch * float(train_params.save_interval[:-5]))\n",
    "else:\n",
    "    save_interval = train_params.save_interval\n",
    "\n",
    "\n",
    "t0 = time.time()\n",
    "total_iter = 0\n",
    "for iep in range(train_params.nepoch):\n",
    "    print(f\"The current lr is {scheduler.get_last_lr()}.\")\n",
    "    for ix in range(ntrain_batch):\n",
    "        net.train()\n",
    "        batch = train_data_loader(ix)\n",
    "        batch = batch.to(df_dtype)\n",
    "\n",
    "        batch_wpos = batch + pos_enc\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        rec_batch = net(batch_wpos)\n",
    "        loss = loss_fn(rec_batch, batch_wpos)\n",
    "        loss_save[\"train\"][\"loss\"].append(loss.item())\n",
    "        loss_save[\"train\"][\"niter\"].append(total_iter)\n",
    "        \n",
    "        #print(\"training:\", net.training)\n",
    "        # Perform backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(net.parameters(), train_params.clip)\n",
    "        # Perform optimization\n",
    "        optimizer.step()\n",
    "        \n",
    "        if ix % train_params.loss_out == (train_params.loss_out-1):\n",
    "            tr_loss = np.mean(loss_save[\"train\"][\"loss\"][-20:])\n",
    "            loss_msg = f\"At iter {total_iter}, the train loss is {tr_loss:.3f}, the time used is {delta_time(t0):.3f}s.\"\n",
    "            print(loss_msg)\n",
    "            t0 = time.time()\n",
    "            net.train()\n",
    "            \n",
    "        if ix % train_params.val_loss_out == (train_params.val_loss_out-1):\n",
    "            res = eval_model_selflearning(trained_model=net,\n",
    "                                          data_loader=val_data_loader,\n",
    "                                          loss_fn=loss_fn,\n",
    "                                          df_dtype=df_dtype,\n",
    "                                          n_batch=20,\n",
    "                                          random=True, \n",
    "                                          verbose=True)\n",
    "            val_loss = np.mean(res) \n",
    "            loss_save[\"val\"][\"loss\"].append(val_loss)\n",
    "            loss_save[\"val\"][\"niter\"].append(total_iter)\n",
    "            loss_msg = f\"At iter {total_iter}, the val loss is {val_loss:.3f}, the time used is {delta_time(t0):.3f}s.\"\n",
    "            print(\"=\"*50)\n",
    "            print(loss_msg)\n",
    "            print(\"=\"*50)\n",
    "            t0 = time.time()\n",
    "            net.train()\n",
    "        \n",
    "        if total_iter % lr_step == (lr_step-1):\n",
    "            scheduler.step()\n",
    "\n",
    "        if total_iter % save_interval == (save_interval-1):\n",
    "            _save_model()\n",
    "            t0 = time.time()\n",
    "\n",
    "    \n",
    "            # save the model \n",
    "        total_iter += 1\n",
    "        #print(\"training:\", net.training)\n",
    "    _save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458651e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
