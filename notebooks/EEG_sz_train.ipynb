{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65afc5c6-4f4d-4c8d-b6fc-2d5bd3dbd2fa",
   "metadata": {},
   "source": [
    "This file is to test my model on the TUH-EEG-seizure data\n",
    "\n",
    "In this file, I train the model with two loss, \n",
    "\n",
    "- loss1: the loss predicting X_t from X_{t-1}\n",
    "- loss2: the loss predicting seizure label from X_t\n",
    "\n",
    "Note that I always discretize X into 2^K classes, so the loss1 is also a classification loss.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db156fe5",
   "metadata": {},
   "source": [
    "# Pre-params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "145684f6-e426-480d-bad6-dd7d86f3b54b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T01:06:49.518438Z",
     "iopub.status.busy": "2024-05-25T01:06:49.517863Z",
     "iopub.status.idle": "2024-05-25T01:06:49.537388Z",
     "shell.execute_reply": "2024-05-25T01:06:49.536748Z",
     "shell.execute_reply.started": "2024-05-25T01:06:49.518395Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my_main_model_dis_base.py'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RUN_PYTHON_SCRIPT = False\n",
    "MODEL_NAME = \"two_loss_autoreg\"\n",
    "SAVED_MODEL = None\n",
    "MODEL_CLASS = \"my_main_model_dis_base.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354c8de0",
   "metadata": {},
   "source": [
    "# Load pkgs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc0c4737-aff1-41f8-a4ca-9c9659dd7512",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T01:06:52.181580Z",
     "iopub.status.busy": "2024-05-25T01:06:52.180738Z",
     "iopub.status.idle": "2024-05-25T01:06:52.357241Z",
     "shell.execute_reply": "2024-05-25T01:06:52.356203Z",
     "shell.execute_reply.started": "2024-05-25T01:06:52.181535Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../mypkg\")\n",
    "from constants import RES_ROOT, FIG_ROOT, DATA_ROOT, MODEL_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd0b2ec3-922a-40d5-ad69-4701aa9ad1fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T01:06:52.534996Z",
     "iopub.status.busy": "2024-05-25T01:06:52.534040Z",
     "iopub.status.idle": "2024-05-25T01:06:54.580506Z",
     "shell.execute_reply": "2024-05-25T01:06:54.579327Z",
     "shell.execute_reply.started": "2024-05-25T01:06:52.534947Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from easydict import EasyDict as edict\n",
    "import time\n",
    "# copy file\n",
    "import shutil\n",
    "from pprint import pprint\n",
    "\n",
    "if not RUN_PYTHON_SCRIPT:\n",
    "    plt.style.use(FIG_ROOT/\"base.mplstyle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "713768d1-2305-4ef8-9473-3672cd14a095",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T01:06:55.004103Z",
     "iopub.status.busy": "2024-05-25T01:06:55.002793Z",
     "iopub.status.idle": "2024-05-25T01:06:55.067510Z",
     "shell.execute_reply": "2024-05-25T01:06:55.066819Z",
     "shell.execute_reply.started": "2024-05-25T01:06:55.004052Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# 0,1, 2, 3, be careful about the space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "612a1577-8d0c-4c34-991f-aecadd00c783",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T01:06:56.114777Z",
     "iopub.status.busy": "2024-05-25T01:06:56.114008Z",
     "iopub.status.idle": "2024-05-25T01:06:56.142165Z",
     "shell.execute_reply": "2024-05-25T01:06:56.141540Z",
     "shell.execute_reply.started": "2024-05-25T01:06:56.114730Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import importlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "870bf723-ebfa-4975-adad-53279ce21e0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T01:07:23.929980Z",
     "iopub.status.busy": "2024-05-25T01:07:23.929525Z",
     "iopub.status.idle": "2024-05-25T01:07:24.589668Z",
     "shell.execute_reply": "2024-05-25T01:07:24.588544Z",
     "shell.execute_reply.started": "2024-05-25T01:07:23.929938Z"
    }
   },
   "outputs": [],
   "source": [
    "from models.my_main_model_dis_base import myNet\n",
    "from models.losses import my_nllloss, ordinal_mse_loss\n",
    "from models.model_utils import generate_position_encode \n",
    "from data_utils.eeg_load_sz import EEGDataSZ\n",
    "from data_utils import digitize_data, rec_data, MyDataLoader\n",
    "from utils.misc import delta_time, load_pkl_folder2dict, save_pkl_dict2folder, truncated_mean_upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c0dd819-8b02-4c78-b283-633dd643a7a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T01:07:26.166126Z",
     "iopub.status.busy": "2024-05-25T01:07:26.165462Z",
     "iopub.status.idle": "2024-05-25T01:07:26.354133Z",
     "shell.execute_reply": "2024-05-25T01:07:26.352949Z",
     "shell.execute_reply.started": "2024-05-25T01:07:26.166082Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pkgs for pytorch (on Apr 3, 2023)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.functional import F\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "torch.set_default_device(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8a8444-1c37-4323-b1d9-bc033dcc584e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e86c794-a9ec-4239-8a21-e0369672fa9a",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e96609",
   "metadata": {},
   "source": [
    "## Model and training params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44d38d87-d50a-45e9-97ff-c2cde38024ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T01:10:52.418879Z",
     "iopub.status.busy": "2024-05-25T01:10:52.417879Z",
     "iopub.status.idle": "2024-05-25T01:10:52.950497Z",
     "shell.execute_reply": "2024-05-25T01:10:52.948980Z",
     "shell.execute_reply.started": "2024-05-25T01:10:52.418829Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if SAVED_MODEL is None:\n",
    "    config = edict()\n",
    "    config.nfeature = 19 # the dim of features at each time point\n",
    "    config.ndim = 256 # the output of the first FC layer\n",
    "    config.dropout = 0.5 # the dropout rate\n",
    "    config.n_layer = 2 # the number of self-attention layers\n",
    "    config.n_head = 8 # numher of heads for multi-head attention\n",
    "    config.is_mask = True # Use mask to make the attention causal\n",
    "    config.is_bias = True # Bias  for layernorm\n",
    "    config.block_size = 256 # the preset length of seq, \n",
    "    config.batch_size = 2 # the batch size\n",
    "    config.move_step = 10 # k, movestep\n",
    "    config.fs = 90\n",
    "    config.target_dim = 19\n",
    "    config.k = 6 # discretize to 2^k levels\n",
    "    config.ncls = 2 # number of classes, 2 for my seizure data\n",
    "    \n",
    "    train_params = edict()\n",
    "    train_params.nepoch= 2\n",
    "    train_params.loss_out = 1\n",
    "    train_params.test_loss_out = 20\n",
    "    train_params.clip = 1 # \n",
    "    # lr step decay, if lr_step is 0, then no decay\n",
    "    # if '1epoch', then decay every epoch\n",
    "    train_params.lr_step = '1epoch'\n",
    "    train_params.lr = 1e-4 \n",
    "    train_params.lr_gamma = 0.1\n",
    "    train_params.lr_weight_decay = 0\n",
    "    train_params.eval_size = 8\n",
    "    # save the model \n",
    "    # if '1epoch', then save every epoch\n",
    "    train_params.save_interval = 1000\n",
    "\n",
    "    # data parameters\n",
    "    data_params = edict()\n",
    "    data_params.move_params=dict(winsize=config.block_size+config.move_step, \n",
    "                     stepsize=config.block_size+config.move_step, \n",
    "                     marginsize=None)\n",
    "    data_params.pre_params=dict(is_detrend=True, \n",
    "                    is_drop=True,\n",
    "                    target_fs=90, \n",
    "                    filter_limit=[1, 45], \n",
    "                    is_diff=False)\n",
    "    data_params.rm_params=dict(rm_len=50,\n",
    "                   keep_len=20)\n",
    "    data_params.subset = \"AR\"\n",
    "\n",
    "else:\n",
    "    saved_model_path = RES_ROOT/SAVED_MODEL\n",
    "    assert saved_model_path.exists(), \"No such model\"\n",
    "    saved_model = load_pkl_folder2dict(saved_model_path)\n",
    "    \n",
    "    config = saved_model.config\n",
    "    train_params = saved_model.train_params\n",
    "    data_params = saved_model.data_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9183517f",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7a74908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of data: train_bckg: 574065, train_sz: 28551, test_bckg: 199910, test_sz: 10461\n"
     ]
    }
   ],
   "source": [
    "verbose = 1\n",
    "move_params = data_params.move_params\n",
    "pre_params = data_params.pre_params\n",
    "rm_params = data_params.rm_params\n",
    "subset = data_params.subset\n",
    "\n",
    "train_data_bckg = EEGDataSZ(\n",
    "    dataset=\"train\", \n",
    "    subset=subset,\n",
    "    label=\"bckg\", \n",
    "    discrete_k=config.k, \n",
    "    verbose=verbose, \n",
    "    move_params=move_params,\n",
    "    pre_params=pre_params,\n",
    "    rm_params=rm_params\n",
    "    )\n",
    "# to generate the cutoff of the background data for discretization\n",
    "train_data_bckg.get_dis_cutoffs();\n",
    "\n",
    "train_data_sz = EEGDataSZ(\n",
    "    dataset=\"train\", \n",
    "    subset=subset,\n",
    "    label=\"sz\", \n",
    "    discrete_k=config.k, \n",
    "    verbose=verbose, \n",
    "    move_params=move_params,\n",
    "    pre_params=pre_params,\n",
    "    rm_params=rm_params\n",
    "    )\n",
    "\n",
    "test_data_bckg = EEGDataSZ(\n",
    "    dataset=\"dev\", \n",
    "    subset=subset,\n",
    "    label=\"bckg\", \n",
    "    discrete_k=config.k, \n",
    "    verbose=verbose, \n",
    "    move_params=move_params,\n",
    "    pre_params=pre_params,\n",
    "    rm_params=rm_params\n",
    "    )\n",
    "\n",
    "test_data_sz = EEGDataSZ(\n",
    "    dataset=\"dev\", \n",
    "    subset=subset,\n",
    "    label=\"sz\", \n",
    "    discrete_k=config.k, \n",
    "    verbose=verbose, \n",
    "    move_params=move_params,\n",
    "    pre_params=pre_params,\n",
    "    rm_params=rm_params\n",
    "    )\n",
    "\n",
    "\n",
    "train_data_bckg_loader = MyDataLoader(train_data_bckg, \n",
    "                                      batch_size=config.batch_size, \n",
    "                                      shuffle=True)\n",
    "train_data_sz_loader = MyDataLoader(train_data_sz, \n",
    "                                    batch_size=config.batch_size, \n",
    "                                    shuffle=True)\n",
    "test_data_bckg_loader = MyDataLoader(test_data_bckg, \n",
    "                                      batch_size=config.batch_size, \n",
    "                                      shuffle=False)\n",
    "test_data_sz_loader = MyDataLoader(test_data_sz, \n",
    "                                    batch_size=config.batch_size, \n",
    "                                    shuffle=False)\n",
    "                                \n",
    "print(f\"Num of data: train_bckg: {len(train_data_bckg)}, train_sz: {len(train_data_sz)}, test_bckg: {len(test_data_bckg)}, test_sz: {len(test_data_sz)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6269c13c",
   "metadata": {},
   "source": [
    "## Prepare training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c478dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans_batch(batch_sz, batch_bckg, shuffle=False):\n",
    "    \"\"\"transform the batch to make it easy for training\n",
    "    args: \n",
    "        - batch_sz: the seizure data batch from the dataloader\n",
    "        - batch_bckg: the background data batch from the dataloader\n",
    "        - shuffle: whether to shuffle the batch\n",
    "    return: res (both seizure and background data)\n",
    "        - res[0]: X_rec, the input of the model \n",
    "        - res[1]: Y_dis, the output of the model, the discrete value\n",
    "        - res[2]: labels, the labels of the data, 1 for seizure, 0 for background\n",
    "    \"\"\"\n",
    "    def _trans_batch_single(batch):\n",
    "        batch_dis, batch_rec = batch\n",
    "\n",
    "        X_rec, Y_rec = batch_rec[:, :-config.move_step], batch_rec[:, config.move_step:]\n",
    "        Y_dis = batch_dis[:, config.move_step:]\n",
    "        Y_move_dis = batch_dis[:, (config.move_step-1):-1] # use X_t as prediction of X_t+1\n",
    "        Y_move_prob = nn.functional.one_hot(Y_move_dis, num_classes=2**config.k).double()\n",
    "        return X_rec, Y_dis\n",
    "\n",
    "    res_sz = _trans_batch_single(batch_sz)\n",
    "    res_bckg = _trans_batch_single(batch_bckg)\n",
    "    labels = torch.cat([torch.ones(res_sz[0].size(0)), torch.zeros(res_bckg[0].size(0))], dim=0).long()\n",
    "    res = []\n",
    "    if shuffle:\n",
    "        n_totol = res_sz[0].size(0) + res_bckg[0].size(0)\n",
    "        idx = torch.randperm(n_totol)\n",
    "        labels = labels[idx]\n",
    "    for re1, re2 in zip(res_sz, res_bckg):\n",
    "        re = torch.cat([re1, re2], dim=0)\n",
    "        if shuffle:\n",
    "            re = re[idx]\n",
    "        res.append(re)\n",
    "    res.append(labels)\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ed6692b-f81b-4023-a3a5-a87e1b9a6913",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T01:10:59.741857Z",
     "iopub.status.busy": "2024-05-25T01:10:59.740911Z",
     "iopub.status.idle": "2024-05-25T01:10:59.793529Z",
     "shell.execute_reply": "2024-05-25T01:10:59.793115Z",
     "shell.execute_reply.started": "2024-05-25T01:10:59.741809Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 1.72M\n"
     ]
    }
   ],
   "source": [
    "pos_enc = generate_position_encode(config.block_size, config.nfeature).unsqueeze(0)\n",
    "loss_fn1 = ordinal_mse_loss\n",
    "# logSoftmax + NLLLoss = CrossEntropyLoss\n",
    "loss_fn2 = nn.NLLLoss() \n",
    "\n",
    "if SAVED_MODEL is None:\n",
    "    net = myNet(config)\n",
    "else:\n",
    "    net = saved_model.model\n",
    "if torch.cuda.is_available():\n",
    "    net = net.cuda()\n",
    "optimizer = torch.optim.Adam(net.parameters(), \n",
    "                             lr=train_params.lr,\n",
    "                             weight_decay=train_params.lr_weight_decay)\n",
    "scheduler = ExponentialLR(optimizer, \n",
    "                          gamma=train_params.lr_gamma);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc6bb884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to evaluate the model on the test data\n",
    "def evaluate(net, test_size=32):\n",
    "    sub_idxs = torch.randint(low=0, high=len(test_data_sz_loader), size=(test_size, ))\n",
    "    losses1 = []\n",
    "    losses2 = []\n",
    "    for sub_idx in sub_idxs:\n",
    "        batch_sz_test = test_data_sz_loader(sub_idx.item())\n",
    "        batch_bckg_test = test_data_bckg_loader(sub_idx.item())\n",
    "        X_rec, Y_dis, szlabels = trans_batch(batch_sz=batch_sz_test, batch_bckg=batch_bckg_test, shuffle=False)\n",
    "        X_rec_wpos = X_rec + pos_enc;\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            probs1, log_probs2 = net(X_rec_wpos)\n",
    "            loss1 = loss_fn1(probs1, Y_dis, num_cls=2**config.k)\n",
    "            loss2 = loss_fn2(log_probs2, szlabels)\n",
    "        losses1.append(loss1.item())\n",
    "        losses2.append(loss2.item())\n",
    "    net.train()\n",
    "    return np.median(losses1), np.median(losses2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923f4998",
   "metadata": {},
   "source": [
    "## training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61b5795f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "{'clip': 1,\n",
      " 'eval_size': 8,\n",
      " 'loss_out': 1,\n",
      " 'lr': 0.0001,\n",
      " 'lr_gamma': 0.1,\n",
      " 'lr_step': '1epoch',\n",
      " 'lr_weight_decay': 0,\n",
      " 'nepoch': 2,\n",
      " 'test_loss_out': 5}\n",
      "{'move_params': {'marginsize': None, 'stepsize': 266, 'winsize': 266},\n",
      " 'pre_params': {'filter_limit': [1, 45],\n",
      "                'is_detrend': True,\n",
      "                'is_diff': False,\n",
      "                'is_drop': True,\n",
      "                'target_fs': 90},\n",
      " 'rm_params': {'keep_len': 20, 'rm_len': 50},\n",
      " 'subset': 'AR'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Start training\")\n",
    "pprint(train_params)\n",
    "pprint(data_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6519005d-6a00-4f5c-9276-f025c00453b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T01:11:12.468981Z",
     "iopub.status.busy": "2024-05-25T01:11:12.468103Z",
     "iopub.status.idle": "2024-05-25T01:11:40.789797Z",
     "shell.execute_reply": "2024-05-25T01:11:40.789097Z",
     "shell.execute_reply.started": "2024-05-25T01:11:12.468934Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current lr is [0.0001].\n",
      "At iter 1/14275, epoch 1, the losses (autoreg-train) are 0.187 . the losses (cls-train) are 0.882 . The time used is 0.291s. \n",
      "At iter 2/14275, epoch 1, the losses (autoreg-train) are 0.250 . the losses (cls-train) are 3.349 . The time used is 0.372s. \n",
      "At iter 3/14275, epoch 1, the losses (autoreg-train) are 0.259 . the losses (cls-train) are 2.373 . The time used is 0.216s. \n",
      "At iter 4/14275, epoch 1, the losses (autoreg-train) are 0.222 . the losses (cls-train) are 2.153 . The time used is 0.474s. \n",
      "At iter 5/14275, epoch 1, the losses (autoreg-train) are 0.247 . the losses (cls-train) are 2.270 . The time used is 0.239s. \n",
      "/data/rajlab1/user_data/jin/MyResearch/EEG-sz-det_dev/notebooks/../mypkg/../results/two_loss_autoreg_epoch1_iter5\n",
      "Create a folder /data/rajlab1/user_data/jin/MyResearch/EEG-sz-det_dev/notebooks/../mypkg/../results/two_loss_autoreg_epoch1_iter5\n",
      "Save to /data/rajlab1/user_data/jin/MyResearch/EEG-sz-det_dev/notebooks/../mypkg/../results/two_loss_autoreg_epoch1_iter5/config.pkl\n",
      "Save to /data/rajlab1/user_data/jin/MyResearch/EEG-sz-det_dev/notebooks/../mypkg/../results/two_loss_autoreg_epoch1_iter5/loss_fns.pkl\n",
      "Save to /data/rajlab1/user_data/jin/MyResearch/EEG-sz-det_dev/notebooks/../mypkg/../results/two_loss_autoreg_epoch1_iter5/loss_save.pkl\n",
      "Save to /data/rajlab1/user_data/jin/MyResearch/EEG-sz-det_dev/notebooks/../mypkg/../results/two_loss_autoreg_epoch1_iter5/train_params.pkl\n",
      "Save to /data/rajlab1/user_data/jin/MyResearch/EEG-sz-det_dev/notebooks/../mypkg/../results/two_loss_autoreg_epoch1_iter5/data_params.pkl\n",
      "At iter 6/14275, epoch 1, the losses (autoreg-train) are 0.242 . the losses (cls-train) are 0.956 . The time used is 0.985s. \n",
      "At iter 7/14275, epoch 1, the losses (autoreg-train) are 0.247 . the losses (cls-train) are 0.020 . The time used is 0.255s. \n",
      "At iter 8/14275, epoch 1, the losses (autoreg-train) are 0.248 . the losses (cls-train) are 3.811 . The time used is 1.110s. \n",
      "At iter 9/14275, epoch 1, the losses (autoreg-train) are 0.261 . the losses (cls-train) are 1.040 . The time used is 0.289s. \n",
      "At iter 10/14275, epoch 1, the losses (autoreg-train) are 0.249 . the losses (cls-train) are 1.109 . The time used is 2.931s. \n",
      "/data/rajlab1/user_data/jin/MyResearch/EEG-sz-det_dev/notebooks/../mypkg/../results/two_loss_autoreg_epoch1_iter10\n",
      "Create a folder /data/rajlab1/user_data/jin/MyResearch/EEG-sz-det_dev/notebooks/../mypkg/../results/two_loss_autoreg_epoch1_iter10\n",
      "Save to /data/rajlab1/user_data/jin/MyResearch/EEG-sz-det_dev/notebooks/../mypkg/../results/two_loss_autoreg_epoch1_iter10/config.pkl\n",
      "Save to /data/rajlab1/user_data/jin/MyResearch/EEG-sz-det_dev/notebooks/../mypkg/../results/two_loss_autoreg_epoch1_iter10/loss_fns.pkl\n",
      "Save to /data/rajlab1/user_data/jin/MyResearch/EEG-sz-det_dev/notebooks/../mypkg/../results/two_loss_autoreg_epoch1_iter10/loss_save.pkl\n",
      "Save to /data/rajlab1/user_data/jin/MyResearch/EEG-sz-det_dev/notebooks/../mypkg/../results/two_loss_autoreg_epoch1_iter10/train_params.pkl\n",
      "Save to /data/rajlab1/user_data/jin/MyResearch/EEG-sz-det_dev/notebooks/../mypkg/../results/two_loss_autoreg_epoch1_iter10/data_params.pkl\n",
      "At iter 11/14275, epoch 1, the losses (autoreg-train) are 0.261 . the losses (cls-train) are 1.306 . The time used is 0.912s. \n",
      "At iter 12/14275, epoch 1, the losses (autoreg-train) are 0.241 . the losses (cls-train) are 1.286 . The time used is 3.469s. \n",
      "At iter 13/14275, epoch 1, the losses (autoreg-train) are 0.217 . the losses (cls-train) are 0.975 . The time used is 1.201s. \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ix \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(train_data_sz_loader)):\n\u001b[1;32m     32\u001b[0m     batch_sz \u001b[38;5;241m=\u001b[39m train_data_sz_loader(ix)\n\u001b[0;32m---> 33\u001b[0m     batch_bckg \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_data_bckg_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     X_rec, Y_dis, szlabels  \u001b[38;5;241m=\u001b[39m trans_batch(batch_sz\u001b[38;5;241m=\u001b[39mbatch_sz, batch_bckg\u001b[38;5;241m=\u001b[39mbatch_bckg, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     35\u001b[0m     X_rec_wpos \u001b[38;5;241m=\u001b[39m X_rec \u001b[38;5;241m+\u001b[39m pos_enc\n",
      "File \u001b[0;32m/data/rajlab1/user_data/jin/MyResearch/EEG-sz-det_dev/notebooks/../mypkg/data_utils/utils.py:145\u001b[0m, in \u001b[0;36mMyDataLoader.__call__\u001b[0;34m(self, ix)\u001b[0m\n\u001b[1;32m    143\u001b[0m batch_dis, batch_rec \u001b[38;5;241m=\u001b[39m [], []\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_idxs[low:up]:\n\u001b[0;32m--> 145\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    146\u001b[0m     batch_dis\u001b[38;5;241m.\u001b[39mappend(batch[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    147\u001b[0m     batch_rec\u001b[38;5;241m.\u001b[39mappend(batch[\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m/data/rajlab1/user_data/jin/MyResearch/EEG-sz-det_dev/notebooks/../mypkg/data_utils/eeg_load_sz.py:218\u001b[0m, in \u001b[0;36mEEGDataSZ.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;66;03m# remove the first and last pts\u001b[39;00m\n\u001b[1;32m    217\u001b[0m data \u001b[38;5;241m=\u001b[39m data[:, \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_params\u001b[38;5;241m.\u001b[39mtarget_fs\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrm_params\u001b[38;5;241m.\u001b[39mrm_len):\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_params\u001b[38;5;241m.\u001b[39mtarget_fs\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrm_params\u001b[38;5;241m.\u001b[39mrm_len)]\n\u001b[0;32m--> 218\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_robust_EEG_rescale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpre_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_fct\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loc_idx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    221\u001b[0m     cur_eff_segs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meff_segs[sub_idx]\n",
      "File \u001b[0;32m/data/rajlab1/user_data/jin/MyResearch/EEG-sz-det_dev/notebooks/../mypkg/data_utils/eeg_load.py:180\u001b[0m, in \u001b[0;36mEEGData._robust_EEG_rescale\u001b[0;34m(self, data, data_max)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"rescale data robustly.\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data_max \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 180\u001b[0m     data_max \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.95\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# to remove the effet of outliers\u001b[39;00m\n\u001b[1;32m    181\u001b[0m data_rescaled \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m/\u001b[39mdata_max\n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m#data_min = -data_max\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;66;03m#data_minmax = 2*(data-data_min)/(data_max-data_min) - 1;\u001b[39;00m\n",
      "File \u001b[0;32m~/jin/conda/envs/eeg-sz-det/lib/python3.9/site-packages/numpy/lib/function_base.py:4543\u001b[0m, in \u001b[0;36mquantile\u001b[0;34m(a, q, axis, out, overwrite_input, method, keepdims, interpolation)\u001b[0m\n\u001b[1;32m   4541\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _quantile_is_valid(q):\n\u001b[1;32m   4542\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuantiles must be in the range [0, 1]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 4543\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_quantile_unchecked\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4544\u001b[0m \u001b[43m    \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jin/conda/envs/eeg-sz-det/lib/python3.9/site-packages/numpy/lib/function_base.py:4555\u001b[0m, in \u001b[0;36m_quantile_unchecked\u001b[0;34m(a, q, axis, out, overwrite_input, method, keepdims)\u001b[0m\n\u001b[1;32m   4547\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_quantile_unchecked\u001b[39m(a,\n\u001b[1;32m   4548\u001b[0m                         q,\n\u001b[1;32m   4549\u001b[0m                         axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4552\u001b[0m                         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   4553\u001b[0m                         keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   4554\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Assumes that q is in [0, 1], and is an ndarray\"\"\"\u001b[39;00m\n\u001b[0;32m-> 4555\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ureduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4556\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_quantile_ureduce_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4557\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4558\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4559\u001b[0m \u001b[43m                    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4560\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4561\u001b[0m \u001b[43m                    \u001b[49m\u001b[43moverwrite_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4562\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jin/conda/envs/eeg-sz-det/lib/python3.9/site-packages/numpy/lib/function_base.py:3823\u001b[0m, in \u001b[0;36m_ureduce\u001b[0;34m(a, func, keepdims, **kwargs)\u001b[0m\n\u001b[1;32m   3820\u001b[0m             index_out \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, ) \u001b[38;5;241m*\u001b[39m nd\n\u001b[1;32m   3821\u001b[0m             kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m out[(\u001b[38;5;28mEllipsis\u001b[39m, ) \u001b[38;5;241m+\u001b[39m index_out]\n\u001b[0;32m-> 3823\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3825\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3826\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/jin/conda/envs/eeg-sz-det/lib/python3.9/site-packages/numpy/lib/function_base.py:4722\u001b[0m, in \u001b[0;36m_quantile_ureduce_func\u001b[0;34m(a, q, axis, out, overwrite_input, method)\u001b[0m\n\u001b[1;32m   4720\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4721\u001b[0m         arr \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m-> 4722\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43m_quantile\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4723\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mquantiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4724\u001b[0m \u001b[43m                   \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4725\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4726\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4727\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/jin/conda/envs/eeg-sz-det/lib/python3.9/site-packages/numpy/lib/function_base.py:4824\u001b[0m, in \u001b[0;36m_quantile\u001b[0;34m(arr, quantiles, axis, method, out)\u001b[0m\n\u001b[1;32m   4820\u001b[0m previous_indexes, next_indexes \u001b[38;5;241m=\u001b[39m _get_indexes(arr,\n\u001b[1;32m   4821\u001b[0m                                               virtual_indexes,\n\u001b[1;32m   4822\u001b[0m                                               values_count)\n\u001b[1;32m   4823\u001b[0m \u001b[38;5;66;03m# --- Sorting\u001b[39;00m\n\u001b[0;32m-> 4824\u001b[0m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartition\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4825\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4826\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mprevious_indexes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4827\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mnext_indexes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4828\u001b[0m \u001b[43m                              \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4829\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4830\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m supports_nans:\n\u001b[1;32m   4831\u001b[0m     slices_having_nans \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39misnan(arr[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training\n",
    "loss1_cur = []\n",
    "loss2_cur = []\n",
    "if SAVED_MODEL is None:\n",
    "    loss_save = edict()\n",
    "    loss_save.train_niter = []\n",
    "    loss_save.test_niter = []\n",
    "    loss_save.train1 = []\n",
    "    loss_save.train2 = []\n",
    "    loss_save.test1 = []\n",
    "    loss_save.test2 = []\n",
    "else:\n",
    "    loss_save = edict(saved_model.loss_save)\n",
    "\n",
    "if isinstance(train_params.lr_step, str):\n",
    "    lr_step = int(len(train_data_sz_loader) * float(train_params.lr_step[:-5]))\n",
    "else:\n",
    "    lr_step = train_params.lr_step\n",
    "if isinstance(train_params.save_interval, str):\n",
    "    save_interval = int(len(train_data_sz_loader) * float(train_params.save_interval[:-5]))\n",
    "else:\n",
    "    save_interval = train_params.save_interval\n",
    "\n",
    "\n",
    "t0 = time.time()\n",
    "total_iter = 0\n",
    "for iep in range(train_params.nepoch):\n",
    "    net.cuda()\n",
    "    net.train()\n",
    "    print(f\"The current lr is {scheduler.get_last_lr()}.\")\n",
    "    for ix in range(len(train_data_sz_loader)):\n",
    "        batch_sz = train_data_sz_loader(ix)\n",
    "        batch_bckg = train_data_bckg_loader(ix)\n",
    "        X_rec, Y_dis, szlabels  = trans_batch(batch_sz=batch_sz, batch_bckg=batch_bckg, shuffle=True)\n",
    "        X_rec_wpos = X_rec + pos_enc\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        probs1, log_probs2 = net(X_rec_wpos)\n",
    "        loss1 = loss_fn1(probs1, Y_dis, num_cls=2**config.k)\n",
    "        loss2 = loss_fn2(log_probs2, szlabels)\n",
    "        # TODO: add weight to the loss\n",
    "        loss = loss1 + loss2\n",
    "        \n",
    "        # Perform backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(net.parameters(), train_params.clip)\n",
    "        # Perform optimization\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss1_cur.append(loss1.item())\n",
    "        loss2_cur.append(loss2.item())\n",
    "        if ix % train_params.loss_out == (train_params.loss_out-1):\n",
    "            loss_save.train_niter.append(total_iter)\n",
    "            loss_save.train1.append(np.median(loss1_cur))\n",
    "            loss_save.train2.append(np.median(loss2_cur))\n",
    "            print(f\"At iter {ix+1}/{len(train_data_sz_loader)}, epoch {iep+1}, \"\n",
    "                  f\"the losses (autoreg-train) are {loss_save.train1[-1]:.3f} . \"\n",
    "                  f\"the losses (cls-train) are {loss_save.train2[-1]:.3f} . \"\n",
    "                  f\"The time used is {delta_time(t0):.3f}s. \"\n",
    "                 )\n",
    "            loss1_cur = []\n",
    "            loss2_cur = []\n",
    "            t0 = time.time()\n",
    "            \n",
    "        if ix % train_params.test_loss_out == (train_params.test_loss_out-1):\n",
    "            loss_save.test_niter.append(total_iter)\n",
    "            loss_test1, loss_test2 = evaluate(net, test_size=train_params.eval_size)\n",
    "            loss_save.test1.append(loss_test1)\n",
    "            loss_save.test2.append(loss_test2)\n",
    "            print(\"=\"*50)\n",
    "            print(f\"At iter {ix+1}/{len(train_data_sz_loader)}, epoch {iep+1}, \"\n",
    "                  f\"the losses (autoreg-test) are {loss_save.test1[-1]:.3f} . \"\n",
    "                  f\"the losses (cls-test) are {loss_save.test2[-1]:.3f} . \"\n",
    "                 )\n",
    "            print(\"=\"*50)\n",
    "        \n",
    "        if total_iter % lr_step == (lr_step-1):\n",
    "            scheduler.step()\n",
    "\n",
    "        if total_iter % save_interval == (save_interval-1):\n",
    "    \n",
    "            # save the model \n",
    "            model_res = edict()\n",
    "            model_res.config = config\n",
    "            model_res.loss_fns = [loss_fn1, loss_fn2]\n",
    "            model_res.loss_save = loss_save\n",
    "            model_res.train_params = train_params\n",
    "            model_res.data_params = data_params\n",
    "    \n",
    "            if SAVED_MODEL is None:\n",
    "                cur_model_name = f\"{MODEL_NAME}_epoch{iep+1}_iter{ix+1}\"\n",
    "            else:\n",
    "                cur_model_name = f\"{MODEL_NAME}_epoch{iep+1}_iter{ix+1}_w_{SAVED_MODEL}\"\n",
    "\n",
    "            save_pkl_dict2folder(RES_ROOT/cur_model_name, model_res, is_force=True)\n",
    "            # save model     \n",
    "            torch.save(net.state_dict(), RES_ROOT/cur_model_name/\"model.pth\")\n",
    "            torch.save(optimizer.state_dict(), RES_ROOT/cur_model_name/\"optimizer.pth\")\n",
    "            torch.save(scheduler.state_dict(), RES_ROOT/cur_model_name/\"scheduler.pth\")\n",
    "            # copy class file \n",
    "            shutil.copy(MODEL_ROOT/MODEL_CLASS, RES_ROOT/cur_model_name/\"model_class.py\")\n",
    "\n",
    "        total_iter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309d2d3b-651f-4793-8dbf-6872c928af4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SSH titan.radiology.ucsf.edu titan-EEG",
   "language": "",
   "name": "rik_ssh_titan_radiology_ucsf_edu_titaneeg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
